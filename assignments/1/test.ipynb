{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data_path = os.path.abspath(os.path.join(\"1\",\"..\", \"..\", \"..\", \"data\", \"external\",'spotify-2' ,\"train.csv\"))\n",
    "test_data_path = os.path.abspath(os.path.join(\"1\",\"..\", \"..\", \"..\", \"data\", \"external\",'spotify-2' ,\"test.csv\"))\n",
    "val_data_path = os.path.abspath(os.path.join(\"1\",\"..\", \"..\", \"..\", \"data\", \"external\",'spotify-2' ,\"validate.csv\"))\n",
    "\n",
    "# using pandas to read the csv file into our dataframe named df\n",
    "df = pd.read_csv(data_path)\n",
    "df_test = pd.read_csv(test_data_path)\n",
    "df_val = pd.read_csv(val_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath('../../models/knn'))\n",
    "from knn import KNNClassifier\n",
    "from knn import Metrics\n",
    "\n",
    "def impute_missing_values(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype.name != 'object':\n",
    "            df[col].fillna(df[col].mean(), inplace=True)\n",
    "        else:\n",
    "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    return df\n",
    "\n",
    "df = impute_missing_values(df)\n",
    "df_test = impute_missing_values(df_test)\n",
    "\n",
    "\n",
    "def custom_label_encoder(train_series, test_series):\n",
    "    unique_vals = train_series.unique()\n",
    "    val_to_int = {val: idx for idx, val in enumerate(unique_vals)}\n",
    "    train_encoded = train_series.map(val_to_int)\n",
    "    test_encoded = test_series.map(val_to_int)\n",
    "    return train_encoded, test_encoded, val_to_int\n",
    "\n",
    "def label_encode_columns(df_train, df_test, columns):\n",
    "    label_encoders = {}\n",
    "    for col in columns:\n",
    "        df_train[col], df_test[col], encoder = custom_label_encoder(df_train[col], df_test[col])\n",
    "        label_encoders[col] = encoder\n",
    "    return df_train, df_test, label_encoders\n",
    "\n",
    "string_columns = ['artists', 'album_name', 'explicit']\n",
    "\n",
    "df, df_test, label_encoders = label_encode_columns(df, df_test, string_columns)\n",
    "\n",
    "\n",
    "df.drop(columns=['track_id', 'track_name','Unnamed: 0'], inplace=True)\n",
    "df_test.drop(columns=['track_id', 'track_name','Unnamed: 0'], inplace=True)\n",
    "\n",
    "\n",
    "df['track_genre'] = df['track_genre'].astype('category').cat.codes\n",
    "df_test['track_genre'] = df_test['track_genre'].astype('category').cat.codes\n",
    "\n",
    "df = impute_missing_values(df)\n",
    "df_test = impute_missing_values(df_test)\n",
    "\n",
    "\n",
    "\n",
    "X_train = df.drop(columns=['track_genre'])\n",
    "X_test = df_test.drop(columns=['track_genre'])\n",
    "y_train = df['track_genre']\n",
    "y_test = df_test['track_genre']\n",
    "\n",
    "def standardize(X_train, X_test, categorical_columns):\n",
    "    # Standardize only numerical columns\n",
    "    num_columns = X_train.columns.difference(categorical_columns)\n",
    "    \n",
    "    mean = X_train[num_columns].mean(axis=0)\n",
    "    std = X_train[num_columns].std(axis=0)\n",
    "    \n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    \n",
    "    X_train_scaled[num_columns] = (X_train[num_columns] - mean) / std\n",
    "    X_test_scaled[num_columns] = (X_test[num_columns] - mean) / std\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "categorical_columns = string_columns\n",
    "\n",
    "X_train_scaled, X_test_scaled = standardize(X_train, X_test, categorical_columns)\n",
    "\n",
    "# X_train_scaled.to_csv('train_cleaned.csv', index=False)\n",
    "# knn = KNNClassifier(k=5, distance_metric='euclidean')\n",
    "# knn.fit(X_train_scaled.values, y_train.values)\n",
    "\n",
    "# # Predict on test data\n",
    "# y_pred = knn.predict(X_test_scaled.values)\n",
    "\n",
    "knn = knn(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "# Calculate and print metrics\n",
    "metrics = Metrics()\n",
    "accuracy = metrics.accuracy(y_test.values, y_pred)\n",
    "precision = metrics.precision(y_test.values, y_pred)\n",
    "recall = metrics.recall(y_test.values, y_pred)\n",
    "f1 = metrics.f1_score(y_test.values, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from itertools import product\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath('../../models/knn'))\n",
    "from knn import KNNClassifier\n",
    "\n",
    "def impute_missing_values(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype.name != 'object':\n",
    "            df[col].fillna(df[col].mean(), inplace=True)\n",
    "        else:\n",
    "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    return df\n",
    "\n",
    "def custom_label_encoder(train_series, test_series, val_series=None):\n",
    "    unique_vals = pd.concat([train_series, test_series, val_series]) if val_series is not None else pd.concat([train_series, test_series])\n",
    "    unique_vals = unique_vals.unique()\n",
    "    val_to_int = {val: idx for idx, val in enumerate(unique_vals)}\n",
    "    train_encoded = train_series.map(val_to_int)\n",
    "    test_encoded = test_series.map(val_to_int)\n",
    "    val_encoded = val_series.map(val_to_int) if val_series is not None else None\n",
    "    return train_encoded, test_encoded, val_encoded, val_to_int\n",
    "\n",
    "def label_encode_columns(df_train, df_test, df_val, columns):\n",
    "    label_encoders = {}\n",
    "    for col in columns:\n",
    "        df_train[col], df_test[col], df_val[col], encoder = custom_label_encoder(df_train[col], df_test[col], df_val[col])\n",
    "        label_encoders[col] = encoder\n",
    "    return df_train, df_test, df_val, label_encoders\n",
    "\n",
    "data_path = os.path.abspath(os.path.join(\"1\", \"..\", \"..\", \"..\", \"data\", \"external\", 'spotify-2', \"train.csv\"))\n",
    "test_data_path = os.path.abspath(os.path.join(\"1\", \"..\", \"..\", \"..\", \"data\", \"external\", 'spotify-2', \"test.csv\"))\n",
    "val_data_path = os.path.abspath(os.path.join(\"1\", \"..\", \"..\", \"..\", \"data\", \"external\", 'spotify-2', \"validate.csv\"))\n",
    "\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "df_test = pd.read_csv(test_data_path)\n",
    "df_val = pd.read_csv(val_data_path)\n",
    "\n",
    "df = impute_missing_values(df)\n",
    "df_test = impute_missing_values(df_test)\n",
    "df_val = impute_missing_values(df_val)\n",
    "\n",
    "string_columns = ['artists', 'album_name', 'explicit']\n",
    "df, df_test, df_val, label_encoders = label_encode_columns(df, df_test, df_val, string_columns)\n",
    "\n",
    "genre_encoder = pd.concat([df['track_genre'], df_test['track_genre'], df_val['track_genre']]).astype('category').cat.codes\n",
    "df['track_genre'] = genre_encoder[:len(df)]\n",
    "df_test['track_genre'] = genre_encoder[len(df):len(df) + len(df_test)]\n",
    "df_val['track_genre'] = genre_encoder[len(df) + len(df_test):]\n",
    "\n",
    "columns_to_drop = ['track_id', 'track_name', 'Unnamed: 0']\n",
    "df.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "df_test.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "df_val.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "# Define features and target\n",
    "X_train = df.drop(columns=['track_genre'])\n",
    "X_test = df_test.drop(columns=['track_genre'])\n",
    "X_val = df_val.drop(columns=['track_genre'])\n",
    "y_train = df['track_genre']\n",
    "y_test = df_test['track_genre']\n",
    "y_val = df_val['track_genre']\n",
    "\n",
    "def standardize(X_train, X_test, X_val, categorical_columns):\n",
    "    num_columns = X_train.columns.difference(categorical_columns)\n",
    "    \n",
    "    mean = X_train[num_columns].mean(axis=0)\n",
    "    std = X_train[num_columns].std(axis=0)\n",
    "    \n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    X_val_scaled = X_val.copy()\n",
    "    \n",
    "    X_train_scaled[num_columns] = (X_train[num_columns] - mean) / std\n",
    "    X_test_scaled[num_columns] = (X_test[num_columns] - mean) / std\n",
    "    X_val_scaled[num_columns] = (X_val[num_columns] - mean) / std\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, X_val_scaled\n",
    "\n",
    "categorical_columns = string_columns\n",
    "X_train_scaled, X_test_scaled, X_val_scaled = standardize(X_train, X_test, X_val, categorical_columns)\n",
    "\n",
    "\n",
    "def evaluate_knn(k, distance_metric):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric=distance_metric)\n",
    "    knn.fit(X_train_scaled.values, y_train.values)\n",
    "    y_pred_val = knn.predict(X_val_scaled.values)\n",
    "    \n",
    "    accuracy = np.mean(y_pred_val == y_val.values)\n",
    "    return accuracy\n",
    "\n",
    "k_values = [1, 3, 5, 7, 9]\n",
    "distance_metrics = ['euclidean', 'manhattan']\n",
    "\n",
    "results = []\n",
    "for k, distance_metric in product(k_values, distance_metrics):\n",
    "    accuracy = evaluate_knn(k, distance_metric)\n",
    "    results.append((k, distance_metric, accuracy))\n",
    "\n",
    "results.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "print(\"Top 10 (k, distance_metric) pairs:\")\n",
    "for i, (k, distance_metric, accuracy) in enumerate(results[:10]):\n",
    "    print(f\"{i+1}. k={k}, distance_metric={distance_metric}, accuracy={accuracy:.4f}\")\n",
    "\n",
    "selected_metric = 'euclidean' \n",
    "ks = [k for k, metric, _ in results if metric == selected_metric]\n",
    "accuracies = [accuracy for k, metric, accuracy in results if metric == selected_metric]\n",
    "\n",
    "plt.plot(ks, accuracies, marker='o')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(f'Accuracy vs k (distance_metric={selected_metric})')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath('../../models/knn'))\n",
    "from knn import KNNClassifier  # Custom KNN classifier implementation\n",
    "\n",
    "# Load data\n",
    "data_path = os.path.abspath(os.path.join(\"1\", \"..\", \"..\", \"..\", \"data\", \"external\", 'spotify-2', \"train.csv\"))\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Function to impute missing values\n",
    "def impute_missing_values(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype.name != 'object':\n",
    "            df[col].fillna(df[col].mean(), inplace=True)\n",
    "        else:\n",
    "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    return df\n",
    "\n",
    "# Impute missing values in the dataset\n",
    "df = impute_missing_values(df)\n",
    "\n",
    "# Label encode categorical columns\n",
    "def custom_label_encoder(series):\n",
    "    unique_vals = series.unique()\n",
    "    val_to_int = {val: idx for idx, val in enumerate(unique_vals)}\n",
    "    encoded = series.map(val_to_int)\n",
    "    return encoded, val_to_int\n",
    "\n",
    "def label_encode_columns(df, columns):\n",
    "    label_encoders = {}\n",
    "    for col in columns:\n",
    "        df[col], encoder = custom_label_encoder(df[col])\n",
    "        label_encoders[col] = encoder\n",
    "    return df, label_encoders\n",
    "\n",
    "string_columns = ['artists', 'album_name', 'explicit']\n",
    "df, label_encoders = label_encode_columns(df, string_columns)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df.drop(columns=['track_id', 'track_name', 'Unnamed: 0'], inplace=True, errors='ignore')\n",
    "\n",
    "# Encode target variable\n",
    "df['track_genre'], genre_encoder = custom_label_encoder(df['track_genre'])\n",
    "\n",
    "# Split the dataset into train, test, and validation sets\n",
    "def train_test_val_split(df, train_size=0.7, test_size=0.15):\n",
    "    np.random.seed(42)\n",
    "    shuffled_indices = np.random.permutation(len(df))\n",
    "    train_end = int(train_size * len(df))\n",
    "    test_end = int(test_size * len(df)) + train_end\n",
    "    \n",
    "    train_indices = shuffled_indices[:train_end]\n",
    "    test_indices = shuffled_indices[train_end:test_end]\n",
    "    val_indices = shuffled_indices[test_end:]\n",
    "    \n",
    "    return df.iloc[train_indices], df.iloc[test_indices], df.iloc[val_indices]\n",
    "\n",
    "df_train, df_test, df_val = train_test_val_split(df)\n",
    "\n",
    "# Define features and target\n",
    "X_train = df_train.drop(columns=['track_genre'])\n",
    "X_test = df_test.drop(columns=['track_genre'])\n",
    "X_val = df_val.drop(columns=['track_genre'])\n",
    "\n",
    "y_train = df_train['track_genre']\n",
    "y_test = df_test['track_genre']\n",
    "y_val = df_val['track_genre']\n",
    "\n",
    "# Standardize numerical features\n",
    "def standardize(X_train, X_test, X_val, categorical_columns):\n",
    "    num_columns = X_train.columns.difference(categorical_columns)\n",
    "    \n",
    "    mean = X_train[num_columns].mean(axis=0)\n",
    "    std = X_train[num_columns].std(axis=0)\n",
    "    \n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    X_val_scaled = X_val.copy()\n",
    "    \n",
    "    X_train_scaled[num_columns] = (X_train[num_columns] - mean) / std\n",
    "    X_test_scaled[num_columns] = (X_test[num_columns] - mean) / std\n",
    "    X_val_scaled[num_columns] = (X_val[num_columns] - mean) / std\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, X_val_scaled\n",
    "\n",
    "X_train_scaled, X_test_scaled, X_val_scaled = standardize(X_train, X_test, X_val, string_columns)\n",
    "\n",
    "def evaluate_knn(k, distance_metric):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric=distance_metric)\n",
    "    knn.fit(X_train_scaled.values, y_train.values)\n",
    "    y_pred_val = knn.predict(X_val_scaled.values)\n",
    "    \n",
    "    accuracy = np.mean(y_pred_val == y_val.values)\n",
    "    return accuracy\n",
    "\n",
    "k_values = [1, 3, 5, 7, 9]\n",
    "distance_metrics = ['euclidean', 'manhattan']\n",
    "\n",
    "results = []\n",
    "for k, distance_metric in product(k_values, distance_metrics):\n",
    "    accuracy = evaluate_knn(k, distance_metric)\n",
    "    results.append((k, distance_metric, accuracy))\n",
    "\n",
    "results.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "print(\"Top 10 (k, distance_metric) pairs:\")\n",
    "for i, (k, distance_metric, accuracy) in enumerate(results[:10]):\n",
    "    print(f\"{i+1}. k={k}, distance_metric={distance_metric}, accuracy={accuracy:.4f}\")\n",
    "\n",
    "selected_metric = 'euclidean' \n",
    "ks = [k for k, metric, _ in results if metric == selected_metric]\n",
    "accuracies = [accuracy for k, metric, accuracy in results if metric == selected_metric]\n",
    "\n",
    "plt.plot(ks, accuracies, marker='o')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(f'Accuracy vs k (distance_metric={selected_metric})')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath('../../models/knn'))\n",
    "from knn import KNNClassifier\n",
    "from knn import Metrics\n",
    "\n",
    "def impute_missing_values(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype.name != 'object':\n",
    "            df[col].fillna(df[col].mean(), inplace=True)\n",
    "        else:\n",
    "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    return df\n",
    "\n",
    "df = impute_missing_values(df)\n",
    "df_test = impute_missing_values(df_test)\n",
    "\n",
    "\n",
    "def custom_label_encoder(train_series, test_series):\n",
    "    unique_vals = train_series.unique()\n",
    "    val_to_int = {val: idx for idx, val in enumerate(unique_vals)}\n",
    "    train_encoded = train_series.map(val_to_int)\n",
    "    test_encoded = test_series.map(val_to_int)\n",
    "    return train_encoded, test_encoded, val_to_int\n",
    "\n",
    "def label_encode_columns(df_train, df_test, columns):\n",
    "    label_encoders = {}\n",
    "    for col in columns:\n",
    "        df_train[col], df_test[col], encoder = custom_label_encoder(df_train[col], df_test[col])\n",
    "        label_encoders[col] = encoder\n",
    "    return df_train, df_test, label_encoders\n",
    "\n",
    "string_columns = ['artists', 'album_name', 'explicit']\n",
    "\n",
    "df, df_test, label_encoders = label_encode_columns(df, df_test, string_columns)\n",
    "\n",
    "\n",
    "df.drop(columns=['track_id', 'track_name','Unnamed: 0'], inplace=True)\n",
    "df_test.drop(columns=['track_id', 'track_name','Unnamed: 0'], inplace=True)\n",
    "\n",
    "\n",
    "df['track_genre'] = df['track_genre'].astype('category').cat.codes\n",
    "df_test['track_genre'] = df_test['track_genre'].astype('category').cat.codes\n",
    "\n",
    "df = impute_missing_values(df)\n",
    "df_test = impute_missing_values(df_test)\n",
    "\n",
    "\n",
    "\n",
    "X_train = df.drop(columns=['track_genre'])\n",
    "X_test = df_test.drop(columns=['track_genre'])\n",
    "y_train = df['track_genre']\n",
    "y_test = df_test['track_genre']\n",
    "\n",
    "def standardize(X_train, X_test, categorical_columns):\n",
    "    # Standardize only numerical columns\n",
    "    num_columns = X_train.columns.difference(categorical_columns)\n",
    "    \n",
    "    mean = X_train[num_columns].mean(axis=0)\n",
    "    std = X_train[num_columns].std(axis=0)\n",
    "    \n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    \n",
    "    X_train_scaled[num_columns] = (X_train[num_columns] - mean) / std\n",
    "    X_test_scaled[num_columns] = (X_test[num_columns] - mean) / std\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "categorical_columns = string_columns\n",
    "\n",
    "X_train_scaled, X_test_scaled = standardize(X_train, X_test, categorical_columns)\n",
    "\n",
    "X_train_scaled.to_csv('train_cleaned.csv', index=False)\n",
    "# knn = KNNClassifier(k=5, distance_metric='euclidean')\n",
    "# knn.fit(X_train_scaled.values, y_train.values)\n",
    "\n",
    "# # Predict on test data\n",
    "# y_pred = knn.predict(X_test_scaled.values)\n",
    "\n",
    "knn = knn(n_neighbors=1)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "# Calculate and print metrics\n",
    "metrics = Metrics()\n",
    "accuracy = Metrics.accuracy(y_test.values, y_pred)\n",
    "precision = Metrics.precision(y_test.values, y_pred)\n",
    "recall = Metrics.recall(y_test.values, y_pred)\n",
    "f1 = Metrics.f1_score(y_test.values, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
