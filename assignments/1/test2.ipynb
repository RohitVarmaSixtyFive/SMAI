{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32097/1704679064.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mean(), inplace=True)\n",
      "/tmp/ipykernel_32097/1704679064.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 132\u001b[0m\n\u001b[1;32m    129\u001b[0m     plot_results(results)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 132\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 123\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m y_train_np \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m    121\u001b[0m y_val_np \u001b[38;5;241m=\u001b[39m y_val\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 123\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtune_hyperparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_np\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop 10 (k, distance_metric) pairs by validation accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (k, distance_metric, accuracy) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results[:\u001b[38;5;241m10\u001b[39m]):\n",
      "Cell \u001b[0;32mIn[2], line 80\u001b[0m, in \u001b[0;36mtune_hyperparameters\u001b[0;34m(X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[1;32m     78\u001b[0m knn \u001b[38;5;241m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[38;5;241m=\u001b[39mk, metric\u001b[38;5;241m=\u001b[39mdistance_metric)\n\u001b[1;32m     79\u001b[0m knn\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m---> 80\u001b[0m y_pred_val \u001b[38;5;241m=\u001b[39m \u001b[43mknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m Metrics\u001b[38;5;241m.\u001b[39maccuracy(y_val, y_pred_val)\n\u001b[1;32m     82\u001b[0m results\u001b[38;5;241m.\u001b[39mappend((k, distance_metric, accuracy))\n",
      "File \u001b[0;32m~/miniconda3/envs/smai/lib/python3.12/site-packages/sklearn/neighbors/_classification.py:271\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(probabilities, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[0;32m--> 271\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/smai/lib/python3.12/site-packages/sklearn/neighbors/_base.py:903\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[1;32m    899\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    900\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m does not work with sparse matrices. Densify the data, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor set algorithm=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method\n\u001b[1;32m    902\u001b[0m         )\n\u001b[0;32m--> 903\u001b[0m     chunked_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_tree_query_parallel_helper\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgen_even_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minternal: _fit_method not recognized\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/smai/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/smai/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/miniconda3/envs/smai/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/miniconda3/envs/smai/lib/python3.12/site-packages/sklearn/utils/parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/smai/lib/python3.12/site-packages/sklearn/neighbors/_base.py:704\u001b[0m, in \u001b[0;36m_tree_query_parallel_helper\u001b[0;34m(tree, *args, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_tree_query_parallel_helper\u001b[39m(tree, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    699\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Helper for the Parallel calls in KNeighborsMixin.kneighbors.\u001b[39;00m\n\u001b[1;32m    700\u001b[0m \n\u001b[1;32m    701\u001b[0m \u001b[38;5;124;03m    The Cython method tree.query is not directly picklable by cloudpickle\u001b[39;00m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;124;03m    under PyPy.\u001b[39;00m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath('../../models/knn'))\n",
    "from knn import KNNClassifier\n",
    "from knn import Metrics\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def load_data():\n",
    "    data_path = os.path.abspath(os.path.join(\"1\", \"..\", \"..\", \"..\", \"data\", \"external\", 'spotify.csv'))\n",
    "    return pd.read_csv(data_path)\n",
    "\n",
    "def impute_missing_values(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype.name != 'object':\n",
    "            df[col].fillna(df[col].mean(), inplace=True)\n",
    "        else:\n",
    "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    return df\n",
    "\n",
    "def custom_label_encoder(series):\n",
    "    unique_vals = series.unique()\n",
    "    val_to_int = {val: idx for idx, val in enumerate(unique_vals)}\n",
    "    encoded = series.map(val_to_int)\n",
    "    return encoded, val_to_int\n",
    "\n",
    "def label_encode_columns(df, columns):\n",
    "    label_encoders = {}\n",
    "    for col in columns:\n",
    "        df[col], encoder = custom_label_encoder(df[col])\n",
    "        label_encoders[col] = encoder\n",
    "    return df, label_encoders\n",
    "\n",
    "def drop_unnecessary_columns(df):\n",
    "    df.drop(columns=['track_id', 'track_name', 'Unnamed: 0', 'artists', 'album_name'], inplace=True, errors='ignore')\n",
    "    return df\n",
    "\n",
    "def encode_target_variable(df):\n",
    "    df['track_genre'], genre_encoder = custom_label_encoder(df['track_genre'])\n",
    "    return df, genre_encoder\n",
    "\n",
    "def train_test_val_split(df, train_size=0.8, test_size=0.1):\n",
    "    np.random.seed(42)\n",
    "    shuffled_indices = np.random.permutation(len(df))\n",
    "    train_end = int(train_size * len(df))\n",
    "    test_end = int(test_size * len(df)) + train_end\n",
    "    \n",
    "    train_indices = shuffled_indices[:train_end]\n",
    "    test_indices = shuffled_indices[train_end:test_end]\n",
    "    val_indices = shuffled_indices[test_end:]\n",
    "    \n",
    "    return df.iloc[train_indices], df.iloc[test_indices], df.iloc[val_indices]\n",
    "\n",
    "def standardize(X_train, X_test, X_val, categorical_columns):\n",
    "    num_columns = X_train.columns.difference(categorical_columns)\n",
    "    mean = X_train[num_columns].mean(axis=0)\n",
    "    std = X_train[num_columns].std(axis=0)\n",
    "    \n",
    "    X_train[num_columns] = (X_train[num_columns] - mean) / std\n",
    "    X_test[num_columns] = (X_test[num_columns] - mean) / std\n",
    "    X_val[num_columns] = (X_val[num_columns] - mean) / std\n",
    "    \n",
    "    return X_train, X_test, X_val\n",
    "\n",
    "def tune_hyperparameters(X_train, y_train, X_val, y_val):\n",
    "    # k_values = [11,13,15,17, 19, 21, 23, 25]\n",
    "    k_values = [19, 21, 23, 25, 27]\n",
    "\n",
    "    distance_metrics = ['euclidean', 'manhattan','cosine']\n",
    "    results = []\n",
    "\n",
    "    for k in k_values:\n",
    "        for distance_metric in distance_metrics:\n",
    "            knn = KNeighborsClassifier(n_neighbors=k, metric=distance_metric)\n",
    "            knn.fit(X_train, y_train)\n",
    "            y_pred_val = knn.predict(X_val)\n",
    "            accuracy = Metrics.accuracy(y_val, y_pred_val)\n",
    "            results.append((k, distance_metric, accuracy))\n",
    "\n",
    "    results.sort(key=lambda x: x[2], reverse=True)\n",
    "    return results\n",
    "\n",
    "def plot_results(results, selected_metric='euclidean'):\n",
    "    ks = [k for k, metric, _ in results if metric == selected_metric]\n",
    "    accuracies = [accuracy for k, metric, accuracy in results if metric == selected_metric]\n",
    "\n",
    "    plt.plot(ks, accuracies, marker='o')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'Accuracy vs k (distance_metric={selected_metric})')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    df = load_data()\n",
    "    df = impute_missing_values(df)\n",
    "    df, label_encoders = label_encode_columns(df, ['explicit'])\n",
    "    df = drop_unnecessary_columns(df)\n",
    "    df, genre_encoder = encode_target_variable(df)\n",
    "    \n",
    "    df_train, df_test, df_val = train_test_val_split(df)\n",
    "    \n",
    "    X_train = df_train.drop(columns=['track_genre'])\n",
    "    X_test = df_test.drop(columns=['track_genre'])\n",
    "    X_val = df_val.drop(columns=['track_genre'])\n",
    "    \n",
    "    y_train = df_train['track_genre']\n",
    "    y_test = df_test['track_genre']\n",
    "    y_val = df_val['track_genre']\n",
    "    \n",
    "    X_train_scaled, X_test_scaled, X_val_scaled = standardize(X_train, X_test, X_val, ['explicit'])\n",
    "    \n",
    "    X_train_np = X_train_scaled.values\n",
    "    X_test_np = X_test_scaled.values\n",
    "    X_val_np = X_val_scaled.values\n",
    "    y_train_np = y_train.values\n",
    "    y_val_np = y_val.values\n",
    "    \n",
    "    results = tune_hyperparameters(X_train_np, y_train_np, X_val_np, y_val_np)\n",
    "    \n",
    "    print(\"Top 10 (k, distance_metric) pairs by validation accuracy:\")\n",
    "    for i, (k, distance_metric, accuracy) in enumerate(results[:10]):\n",
    "        print(f\"{i+1}. k={k}, distance_metric={distance_metric}, accuracy={accuracy:.4f}\")\n",
    "    \n",
    "    plot_results(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append(os.path.abspath('../../models/knn'))\n",
    "from knn import KNNClassifier\n",
    "from knn import Metrics\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def load_data():\n",
    "    data_path = os.path.abspath(os.path.join(\"1\", \"..\", \"..\", \"..\", \"data\", \"external\", 'spotify.csv'))\n",
    "    return pd.read_csv(data_path)\n",
    "\n",
    "def impute_missing_values(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype.name != 'object':\n",
    "            df[col].fillna(df[col].mean(), inplace=True)\n",
    "        else:\n",
    "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    return df\n",
    "\n",
    "def custom_label_encoder(series):\n",
    "    unique_vals = series.unique()\n",
    "    val_to_int = {val: idx for idx, val in enumerate(unique_vals)}\n",
    "    encoded = series.map(val_to_int)\n",
    "    return encoded, val_to_int\n",
    "\n",
    "def label_encode_columns(df, columns):\n",
    "    label_encoders = {}\n",
    "    for col in columns:\n",
    "        df[col], encoder = custom_label_encoder(df[col])\n",
    "        label_encoders[col] = encoder\n",
    "    return df, label_encoders\n",
    "\n",
    "def drop_unnecessary_columns(df):\n",
    "    df.drop(columns=['track_id', 'track_name', 'Unnamed: 0', 'artists', 'album_name'], inplace=True, errors='ignore')\n",
    "    return df\n",
    "\n",
    "def encode_target_variable(df):\n",
    "    df['track_genre'], genre_encoder = custom_label_encoder(df['track_genre'])\n",
    "    return df, genre_encoder\n",
    "\n",
    "def train_test_val_split(df, train_size=0.8, test_size=0.1):\n",
    "    np.random.seed(42)\n",
    "    shuffled_indices = np.random.permutation(len(df))\n",
    "    train_end = int(train_size * len(df))\n",
    "    test_end = int(test_size * len(df)) + train_end\n",
    "    \n",
    "    train_indices = shuffled_indices[:train_end]\n",
    "    test_indices = shuffled_indices[train_end:test_end]\n",
    "    val_indices = shuffled_indices[test_end:]\n",
    "    \n",
    "    return df.iloc[train_indices], df.iloc[test_indices], df.iloc[val_indices]\n",
    "\n",
    "def standardize(X_train, X_test, X_val, categorical_columns):\n",
    "    num_columns = X_train.columns.difference(categorical_columns)\n",
    "    mean = X_train[num_columns].mean(axis=0)\n",
    "    std = X_train[num_columns].std(axis=0)\n",
    "    \n",
    "    X_train[num_columns] = (X_train[num_columns] - mean) / std\n",
    "    X_test[num_columns] = (X_test[num_columns] - mean) / std\n",
    "    X_val[num_columns] = (X_val[num_columns] - mean) / std\n",
    "    \n",
    "    return X_train, X_test, X_val\n",
    "\n",
    "def train_data(X_train, y_train, X_val, y_val):\n",
    "    k_values = [23]\n",
    "    distance_metrics = ['manhattan']\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for k in k_values:\n",
    "        for distance_metric in distance_metrics:\n",
    "            knn = KNNClassifier(k=k, distance_metric=distance_metric)\n",
    "            knn.fit(X_train, y_train)\n",
    "            \n",
    "            # Measure inference time\n",
    "            start_time = time.time()\n",
    "            y_pred_val = knn.predict(X_val)\n",
    "            end_time = time.time()\n",
    "            inference_time = end_time - start_time\n",
    "            \n",
    "            accuracy = Metrics.accuracy(y_val, y_pred_val)\n",
    "            precision = Metrics.precision(y_val, y_pred_val)\n",
    "            recall = Metrics.recall(y_val, y_pred_val)\n",
    "            f1_score = Metrics.f1_score(y_val, y_pred_val)\n",
    "\n",
    "            results.append((k, distance_metric, accuracy, precision, recall, f1_score, inference_time))\n",
    "\n",
    "    results.sort(key=lambda x: x[2], reverse=True)\n",
    "    return results\n",
    "\n",
    "def plot_results(results, selected_metric='euclidean'):\n",
    "    ks = [k for k, metric, _ in results if metric == selected_metric]\n",
    "    accuracies = [accuracy for k, metric, accuracy in results if metric == selected_metric]\n",
    "\n",
    "    plt.plot(ks, accuracies, marker='o')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'Accuracy vs k (distance_metric={selected_metric})')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    df = load_data()\n",
    "    df = impute_missing_values(df)\n",
    "    df, label_encoders = label_encode_columns(df, ['explicit'])\n",
    "    df = drop_unnecessary_columns(df)\n",
    "    df, genre_encoder = encode_target_variable(df)\n",
    "    df_train, df_test, df_val = train_test_val_split(df)\n",
    "    \n",
    "    X_train = df_train.drop(columns=['track_genre'])\n",
    "    X_test = df_test.drop(columns=['track_genre'])\n",
    "    X_val = df_val.drop(columns=['track_genre'])\n",
    "    \n",
    "    y_train = df_train['track_genre']\n",
    "    y_test = df_test['track_genre']\n",
    "    y_val = df_val['track_genre']\n",
    "    \n",
    "    X_train_scaled, X_test_scaled, X_val_scaled = standardize(X_train, X_test, X_val, ['explicit'])\n",
    "    \n",
    "    X_train_np = X_train_scaled.values\n",
    "    X_test_np = X_test_scaled.values\n",
    "    X_val_np = X_val_scaled.values\n",
    "    y_train_np = y_train.values\n",
    "    y_val_np = y_val.values\n",
    "    \n",
    "    results = train_data(X_train_np, y_train_np, X_val_np, y_val_np)\n",
    "    \n",
    "    print(f\"{'k':<5} {'Distance':<12} {'Acc':<10} {'Prec':<10} {'Recall':<10} {'F1':<10} {'Time (s)':<10}\")\n",
    "    for k, distance_metric, accuracy, precision, recall, f1, inference_time in results[:10]:\n",
    "        print(f\"{k:<5} {distance_metric:<12} {accuracy:<10.4f} {precision:<10.4f} {recall:<10.4f} {f1:<10.4f} {inference_time:<10.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.553794860839844e-05\n",
      "Accuracy: 0.2503\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys,os\n",
    "sys.path.append(os.path.abspath('../../models/knn'))\n",
    "from knn import KNNClassifier\n",
    "# from knn import Metrics\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def load_data():\n",
    "    data_path = os.path.abspath(os.path.join(\"1\", \"..\", \"..\", \"..\", \"data\", \"external\", 'spotify.csv'))\n",
    "    return pd.read_csv(data_path)\n",
    "\n",
    "def impute_missing_values(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype.name != 'object':\n",
    "            df[col].fillna(df[col].mean(), inplace=True)\n",
    "        else:\n",
    "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    return df\n",
    "\n",
    "def custom_label_encoder(series):\n",
    "    unique_vals = series.unique()\n",
    "    val_to_int = {val: idx for idx, val in enumerate(unique_vals)}\n",
    "    encoded = series.map(val_to_int)\n",
    "    return encoded, val_to_int\n",
    "\n",
    "def label_encode_columns(df, columns):\n",
    "    label_encoders = {}\n",
    "    for col in columns:\n",
    "        df[col], encoder = custom_label_encoder(df[col])\n",
    "        label_encoders[col] = encoder\n",
    "    return df, label_encoders\n",
    "\n",
    "def drop_unnecessary_columns(df):\n",
    "    df.drop(columns=['track_id', 'track_name', 'Unnamed: 0', 'artists', 'album_name'], inplace=True, errors='ignore')\n",
    "    return df\n",
    "\n",
    "def encode_target_variable(df):\n",
    "    df['track_genre'], genre_encoder = custom_label_encoder(df['track_genre'])\n",
    "    return df, genre_encoder\n",
    "\n",
    "def train_test_val_split(df, train_size=0.8, test_size=0.1):\n",
    "    np.random.seed(42)\n",
    "    shuffled_indices = np.random.permutation(len(df))\n",
    "    train_end = int(train_size * len(df))\n",
    "    test_end = int(test_size * len(df)) + train_end\n",
    "    \n",
    "    train_indices = shuffled_indices[:train_end]\n",
    "    test_indices = shuffled_indices[train_end:test_end]\n",
    "    val_indices = shuffled_indices[test_end:]\n",
    "    \n",
    "    return df.iloc[train_indices], df.iloc[test_indices], df.iloc[val_indices]\n",
    "\n",
    "def standardize(X_train, X_test, X_val, categorical_columns):\n",
    "    num_columns = X_train.columns.difference(categorical_columns)\n",
    "    mean = X_train[num_columns].mean(axis=0)\n",
    "    std = X_train[num_columns].std(axis=0)\n",
    "    \n",
    "    X_train[num_columns] = (X_train[num_columns] - mean) / std\n",
    "    X_test[num_columns] = (X_test[num_columns] - mean) / std\n",
    "    X_val[num_columns] = (X_val[num_columns] - mean) / std\n",
    "    \n",
    "    return X_train, X_test, X_val\n",
    "\n",
    "def train_data(X_train, y_train, X_val, y_val):\n",
    "    k_values = [23]\n",
    "    distance_metrics = ['manhattan']\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for k in k_values:\n",
    "        for distance_metric in distance_metrics:\n",
    "            knn = KNNClassifier(k=k, distance_metric=distance_metric)\n",
    "            knn.fit(X_train, y_train)\n",
    "            \n",
    "            # Measure inference time\n",
    "            start_time = time.time()\n",
    "            y_pred_val = knn.predict(X_val)\n",
    "            end_time = time.time()\n",
    "            inference_time = end_time - start_time\n",
    "            \n",
    "            accuracy = Metrics.accuracy(y_val, y_pred_val)\n",
    "            precision = Metrics.precision(y_val, y_pred_val)\n",
    "            recall = Metrics.recall(y_val, y_pred_val)\n",
    "            f1_score = Metrics.f1_score(y_val, y_pred_val)\n",
    "\n",
    "            results.append((k, distance_metric, accuracy, precision, recall, f1_score, inference_time))\n",
    "\n",
    "    results.sort(key=lambda x: x[2], reverse=True)\n",
    "    return results\n",
    "\n",
    "def plot_results(results, selected_metric='euclidean'):\n",
    "    ks = [k for k, metric, _ in results if metric == selected_metric]\n",
    "    accuracies = [accuracy for k, metric, accuracy in results if metric == selected_metric]\n",
    "\n",
    "    plt.plot(ks, accuracies, marker='o')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'Accuracy vs k (distance_metric={selected_metric})')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "df = load_data()\n",
    "df = impute_missing_values(df)\n",
    "df, label_encoders = label_encode_columns(df, ['explicit'])\n",
    "df = drop_unnecessary_columns(df)\n",
    "df, genre_encoder = encode_target_variable(df)\n",
    "df_train, df_test, df_val = train_test_val_split(df)\n",
    "\n",
    "X_train = df_train.drop(columns=['track_genre'])\n",
    "X_test = df_test.drop(columns=['track_genre'])\n",
    "X_val = df_val.drop(columns=['track_genre'])\n",
    "\n",
    "y_train = df_train['track_genre']\n",
    "y_test = df_test['track_genre']\n",
    "y_val = df_val['track_genre']\n",
    "\n",
    "X_train_scaled, X_test_scaled, X_val_scaled = standardize(X_train, X_test, X_val, ['explicit'])\n",
    "\n",
    "X_train_np = X_train_scaled.values\n",
    "X_test_np = X_test_scaled.values\n",
    "X_val_np = X_val_scaled.values\n",
    "y_train_np = y_train.values\n",
    "y_val_np = y_val.values\n",
    "\n",
    "t1 = time.time()\n",
    "knn = KNNClassifier(k=23, distance_metric='manhattan')\n",
    "knn.fit(X_train_np, y_train_np)\n",
    "t2 = time.time()\n",
    "\n",
    "print(t1 - t2)\n",
    "\n",
    "y_pred = knn.predict(X_test_np)\n",
    "\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
