{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25497/2082034427.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mean(), inplace=True)\n",
      "/tmp/ipykernel_25497/2082034427.py:39: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 159\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<5\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdistance_metric\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<12\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<10.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<10.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<10.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<10.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minference_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<10.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 159\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 152\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m X_train_scaled, X_test_scaled, X_val_scaled \u001b[38;5;241m=\u001b[39m standardize(X_train, X_test, X_val, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexplicit\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    150\u001b[0m X_train_pca, X_test_pca, X_val_pca \u001b[38;5;241m=\u001b[39m apply_pca(X_train_scaled\u001b[38;5;241m.\u001b[39mvalues, X_test_scaled\u001b[38;5;241m.\u001b[39mvalues, X_val_scaled\u001b[38;5;241m.\u001b[39mvalues, n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)\n\u001b[0;32m--> 152\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_pca\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_pca\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<5\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistance\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<12\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAcc\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrec\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecall\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF1\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime (s)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, distance_metric, accuracy, precision, recall, f1, inference_time \u001b[38;5;129;01min\u001b[39;00m results[:\u001b[38;5;241m10\u001b[39m]:\n",
      "Cell \u001b[0;32mIn[1], line 118\u001b[0m, in \u001b[0;36mtrain_data\u001b[0;34m(X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Measure inference time\u001b[39;00m\n\u001b[1;32m    117\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 118\u001b[0m y_pred_val \u001b[38;5;241m=\u001b[39m \u001b[43mknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    120\u001b[0m inference_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/Desktop/SMAI/smai-m24-assignments-RohitVarmaSixtyFive/models/knn/knn.py:58\u001b[0m, in \u001b[0;36mKNNClassifier.predict\u001b[0;34m(self, X_test)\u001b[0m\n\u001b[1;32m     55\u001b[0m X_test_batch \u001b[38;5;241m=\u001b[39m X_test[start:end]\n\u001b[1;32m     57\u001b[0m distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_distances_batch(X_test_batch)\n\u001b[0;32m---> 58\u001b[0m k_nearest_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_nearest_neighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistances\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m k_nearest_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train[k_nearest_indices]\n\u001b[1;32m     60\u001b[0m predictions[start:end] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vote(k_nearest_labels)\n",
      "File \u001b[0;32m~/Desktop/SMAI/smai-m24-assignments-RohitVarmaSixtyFive/models/knn/knn.py:36\u001b[0m, in \u001b[0;36mKNNClassifier._get_nearest_neighbors\u001b[0;34m(self, distances)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_nearest_neighbors\u001b[39m(\u001b[38;5;28mself\u001b[39m, distances):\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margsort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[:, :\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk]\n",
      "File \u001b[0;32m~/miniconda3/envs/smai/lib/python3.12/site-packages/numpy/core/fromnumeric.py:1133\u001b[0m, in \u001b[0;36margsort\u001b[0;34m(a, axis, kind, order)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_argsort_dispatcher)\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21margsort\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;124;03m    Returns the indices that would sort an array.\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \n\u001b[1;32m   1132\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margsort\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/smai/lib/python3.12/site-packages/numpy/core/fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath('../../models/knn'))\n",
    "from knn import KNNClassifier\n",
    "from knn import Metrics\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', '..')))  \n",
    "import matplotlib.pyplot as plt\n",
    "from models.PCA.PCA import PCA\n",
    "from models.Kmeans.Kmeans import Kmeans\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "sys.path.append(os.path.abspath('../../models/knn'))\n",
    "from knn import KNNClassifier\n",
    "from knn import Metrics\n",
    "\n",
    "def load_data():\n",
    "    data_path = os.path.abspath(os.path.join(\"1\", \"..\", \"..\", \"..\", \"data\", \"external\", 'spotify.csv'))\n",
    "    return pd.read_csv(data_path)\n",
    "\n",
    "def impute_missing_values(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype.name != 'object':\n",
    "            df[col].fillna(df[col].mean(), inplace=True)\n",
    "        else:\n",
    "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    return df\n",
    "\n",
    "def custom_label_encoder(series):\n",
    "    unique_vals = series.unique()\n",
    "    val_to_int = {val: idx for idx, val in enumerate(unique_vals)}\n",
    "    encoded = series.map(val_to_int)\n",
    "    return encoded, val_to_int\n",
    "\n",
    "def label_encode_columns(df, columns):\n",
    "    label_encoders = {}\n",
    "    for col in columns:\n",
    "        df[col], encoder = custom_label_encoder(df[col])\n",
    "        label_encoders[col] = encoder\n",
    "    return df, label_encoders\n",
    "\n",
    "def drop_unnecessary_columns(df):\n",
    "    df.drop(columns=['track_id', 'track_name', 'Unnamed: 0', 'artists', 'album_name'], inplace=True, errors='ignore')\n",
    "    return df\n",
    "\n",
    "def encode_target_variable(df):\n",
    "    df['track_genre'], genre_encoder = custom_label_encoder(df['track_genre'])\n",
    "    return df, genre_encoder\n",
    "\n",
    "def train_test_val_split(df, train_size=0.8, test_size=0.1):\n",
    "    np.random.seed(42)\n",
    "    shuffled_indices = np.random.permutation(len(df))\n",
    "    train_end = int(train_size * len(df))\n",
    "    test_end = int(test_size * len(df)) + train_end\n",
    "    \n",
    "    train_indices = shuffled_indices[:train_end]\n",
    "    test_indices = shuffled_indices[train_end:test_end]\n",
    "    val_indices = shuffled_indices[test_end:]\n",
    "    \n",
    "    return df.iloc[train_indices], df.iloc[test_indices], df.iloc[val_indices]\n",
    "\n",
    "def standardize(X_train, X_test, X_val, categorical_columns):\n",
    "    num_columns = X_train.columns.difference(categorical_columns)\n",
    "    mean = X_train[num_columns].mean(axis=0)\n",
    "    std = X_train[num_columns].std(axis=0)\n",
    "    \n",
    "    X_train[num_columns] = (X_train[num_columns] - mean) / std\n",
    "    X_test[num_columns] = (X_test[num_columns] - mean) / std\n",
    "    X_val[num_columns] = (X_val[num_columns] - mean) / std\n",
    "    \n",
    "    return X_train, X_test, X_val\n",
    "\n",
    "def apply_pca(X_train, X_test, X_val, n_components=7):\n",
    "    \n",
    "    pca = PCA(n_components=n_components)\n",
    "    \n",
    "    pca.fit(X_train)\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    \n",
    "    # pca.fit(X_test)\n",
    "    X_test_pca =  pca.transform(X_test)\n",
    "    \n",
    "    # pca.fit(X_val)\n",
    "    X_val_pca = pca.transform(X_val)\n",
    "    \n",
    "    # X_train_pca = pca.fit_transform(X_train)\n",
    "    # X_test_pca = pca.transform(X_test)\n",
    "    # X_val_pca = pca.transform(X_val)\n",
    "    \n",
    "    return X_train_pca, X_test_pca, X_val_pca\n",
    "\n",
    "def train_data(X_train, y_train, X_val, y_val):\n",
    "    k_values = [23]\n",
    "    distance_metrics = ['manhattan']\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for k in k_values:\n",
    "        for distance_metric in distance_metrics:\n",
    "            knn = KNNClassifier(k=k, distance_metric=distance_metric)\n",
    "            knn.fit(X_train, y_train)\n",
    "            \n",
    "            # Measure inference time\n",
    "            start_time = time.time()\n",
    "            y_pred_val = knn.predict(X_val)\n",
    "            end_time = time.time()\n",
    "            inference_time = end_time - start_time\n",
    "            \n",
    "            accuracy = Metrics.accuracy(y_val, y_pred_val)\n",
    "            precision = Metrics.precision(y_val, y_pred_val)\n",
    "            recall = Metrics.recall(y_val, y_pred_val)\n",
    "            f1_score = Metrics.f1_score(y_val, y_pred_val)\n",
    "\n",
    "            results.append((k, distance_metric, accuracy, precision, recall, f1_score, inference_time))\n",
    "\n",
    "    results.sort(key=lambda x: x[2], reverse=True)\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    df = load_data()\n",
    "    df = impute_missing_values(df)\n",
    "    df, label_encoders = label_encode_columns(df, ['explicit'])\n",
    "    df = drop_unnecessary_columns(df)\n",
    "    df, genre_encoder = encode_target_variable(df)\n",
    "    df_train, df_test, df_val = train_test_val_split(df)\n",
    "    \n",
    "    X_train = df_train.drop(columns=['track_genre'])\n",
    "    X_test = df_test.drop(columns=['track_genre'])\n",
    "    X_val = df_val.drop(columns=['track_genre'])\n",
    "    \n",
    "    y_train = df_train['track_genre']\n",
    "    y_test = df_test['track_genre']\n",
    "    y_val = df_val['track_genre']\n",
    "    \n",
    "    X_train_scaled, X_test_scaled, X_val_scaled = standardize(X_train, X_test, X_val, ['explicit'])\n",
    "    \n",
    "    X_train_pca, X_test_pca, X_val_pca = apply_pca(X_train_scaled.values, X_test_scaled.values, X_val_scaled.values, n_components=7)\n",
    "    \n",
    "    results = train_data(X_train_pca, y_train.values, X_val_pca, y_val.values)\n",
    "    \n",
    "    print(f\"{'k':<5} {'Distance':<12} {'Acc':<10} {'Prec':<10} {'Recall':<10} {'F1':<10} {'Time (s)':<10}\")\n",
    "    for k, distance_metric, accuracy, precision, recall, f1, inference_time in results[:10]:\n",
    "        print(f\"{k:<5} {distance_metric:<12} {accuracy:<10.4f} {precision:<10.4f} {recall:<10.4f} {f1:<10.4f} {inference_time:<10.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath('../../models/knn'))\n",
    "from knn import KNNClassifier\n",
    "from knn import Metrics\n",
    "\n",
    "def load_data():\n",
    "    data_path = os.path.abspath(os.path.join(\"1\", \"..\", \"..\", \"..\", \"data\", \"external\", 'spotify.csv'))\n",
    "    return pd.read_csv(data_path)\n",
    "\n",
    "def impute_missing_values(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype.name != 'object':\n",
    "            df[col].fillna(df[col].mean(), inplace=True)\n",
    "        else:\n",
    "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    return df\n",
    "\n",
    "def custom_label_encoder(series):\n",
    "    unique_vals = series.unique()\n",
    "    val_to_int = {val: idx for idx, val in enumerate(unique_vals)}\n",
    "    encoded = series.map(val_to_int)\n",
    "    return encoded, val_to_int\n",
    "\n",
    "def label_encode_columns(df, columns):\n",
    "    label_encoders = {}\n",
    "    for col in columns:\n",
    "        df[col], encoder = custom_label_encoder(df[col])\n",
    "        label_encoders[col] = encoder\n",
    "    return df, label_encoders\n",
    "\n",
    "def drop_unnecessary_columns(df):\n",
    "    df.drop(columns=['track_id', 'track_name', 'Unnamed: 0', 'artists', 'album_name'], inplace=True, errors='ignore')\n",
    "    return df\n",
    "\n",
    "def encode_target_variable(df):\n",
    "    df['track_genre'], genre_encoder = custom_label_encoder(df['track_genre'])\n",
    "    return df, genre_encoder\n",
    "\n",
    "def train_test_val_split(df, train_size=0.8, test_size=0.1):\n",
    "    np.random.seed(42)\n",
    "    shuffled_indices = np.random.permutation(len(df))\n",
    "    train_end = int(train_size * len(df))\n",
    "    test_end = int(test_size * len(df)) + train_end\n",
    "    \n",
    "    train_indices = shuffled_indices[:train_end]\n",
    "    test_indices = shuffled_indices[train_end:test_end]\n",
    "    val_indices = shuffled_indices[test_end:]\n",
    "    \n",
    "    return df.iloc[train_indices], df.iloc[test_indices], df.iloc[val_indices]\n",
    "\n",
    "def standardize(X_train, X_test, X_val, categorical_columns):\n",
    "    num_columns = X_train.columns.difference(categorical_columns)\n",
    "    mean = X_train[num_columns].mean(axis=0)\n",
    "    std = X_train[num_columns].std(axis=0)\n",
    "    \n",
    "    X_train[num_columns] = (X_train[num_columns] - mean) / std\n",
    "    X_test[num_columns] = (X_test[num_columns] - mean) / std\n",
    "    X_val[num_columns] = (X_val[num_columns] - mean) / std\n",
    "    \n",
    "    return X_train, X_test, X_val\n",
    "\n",
    "def apply_pca(X_train, X_test, X_val, n_components=7):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(X_train)\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    X_val_pca = pca.transform(X_val)\n",
    "    return X_train_pca, X_test_pca, X_val_pca\n",
    "\n",
    "def train_data(X_train, y_train, X_val, y_val):\n",
    "    k_values = range(1, 31)\n",
    "    distance_metrics = ['manhattan', 'cosine', 'euclidean']\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for k in k_values:\n",
    "        for distance_metric in distance_metrics:\n",
    "            knn = KNNClassifier(k=k, metric=distance_metric)\n",
    "            knn.fit(X_train, y_train)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            y_pred_val = knn.predict(X_val)\n",
    "            end_time = time.time()\n",
    "            inference_time = end_time - start_time\n",
    "            \n",
    "            accuracy = Metrics.accuracy(y_val, y_pred_val)\n",
    "            precision = Metrics.precision(y_val, y_pred_val)\n",
    "            recall = Metrics.recall(y_val, y_pred_val)\n",
    "            f1_score = Metrics.f1_score(y_val, y_pred_val)\n",
    "\n",
    "            results.append((k, distance_metric, accuracy, precision, recall, f1_score, inference_time))\n",
    "\n",
    "    results.sort(key=lambda x: x[2], reverse=True)  # Sort by accuracy\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    df = load_data()\n",
    "    df = impute_missing_values(df)\n",
    "    df, label_encoders = label_encode_columns(df, ['explicit'])\n",
    "    df = drop_unnecessary_columns(df)\n",
    "    df, genre_encoder = encode_target_variable(df)\n",
    "    df_train, df_test, df_val = train_test_val_split(df)\n",
    "    \n",
    "    X_train = df_train.drop(columns=['track_genre'])\n",
    "    X_test = df_test.drop(columns=['track_genre'])\n",
    "    X_val = df_val.drop(columns=['track_genre'])\n",
    "    \n",
    "    y_train = df_train['track_genre']\n",
    "    y_test = df_test['track_genre']\n",
    "    y_val = df_val['track_genre']\n",
    "    \n",
    "    X_train_scaled, X_test_scaled, X_val_scaled = standardize(X_train, X_test, X_val, ['explicit'])\n",
    "    \n",
    "    X_train_pca, X_test_pca, X_val_pca = apply_pca(X_train_scaled.values, X_test_scaled.values, X_val_scaled.values, n_components=7)\n",
    "    \n",
    "    results = train_data(X_train_pca, y_train.values, X_val_pca, y_val.values)\n",
    "    \n",
    "    # Print top 10 best results\n",
    "    print(f\"{'k':<5} {'Distance':<12} {'Acc':<10} {'Prec':<10} {'Recall':<10} {'F1':<10} {'Time (s)':<10}\")\n",
    "    for k, distance_metric, accuracy, precision, recall, f1, inference_time in results[:10]:\n",
    "        print(f\"{k:<5} {distance_metric:<12} {accuracy:<10.4f} {precision:<10.4f} {recall:<10.4f} {f1:<10.4f} {inference_time:<10.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results, header=\"\"):\n",
    "    print(f\"\\n{header}\")\n",
    "    print(f\"{'k':<5} {'Distance':<12} {'Acc':<10} {'Prec':<10} {'Recall':<10} {'F1':<10} {'Time (s)':<10}\")\n",
    "    for k, distance_metric, accuracy, precision, recall, f1, inference_time in results[:10]:\n",
    "        print(f\"{k:<5} {distance_metric:<12} {accuracy:<10.4f} {precision:<10.4f} {recall:<10.4f} {f1:<10.4f} {inference_time:<10.4f}\")\n",
    "\n",
    "def compare_pca_vs_non_pca():\n",
    "    # Load and preprocess the data\n",
    "    df = load_data()\n",
    "    df = impute_missing_values(df)\n",
    "    df, label_encoders = label_encode_columns(df, ['explicit'])\n",
    "    df = drop_unnecessary_columns(df)\n",
    "    df, genre_encoder = encode_target_variable(df)\n",
    "    df_train, df_test, df_val = train_test_val_split(df)\n",
    "    \n",
    "    X_train = df_train.drop(columns=['track_genre'])\n",
    "    X_test = df_test.drop(columns=['track_genre'])\n",
    "    X_val = df_val.drop(columns=['track_genre'])\n",
    "    \n",
    "    y_train = df_train['track_genre']\n",
    "    y_test = df_test['track_genre']\n",
    "    y_val = df_val['track_genre']\n",
    "    \n",
    "    X_train_scaled, X_test_scaled, X_val_scaled = standardize(X_train, X_test, X_val, ['explicit'])\n",
    "    \n",
    "    results_without_pca = train_data(X_train_scaled.values, y_train.values, X_val_scaled.values, y_val.values)\n",
    "    \n",
    "    X_train_pca, X_test_pca, X_val_pca = apply_pca(X_train_scaled.values, X_test_scaled.values, X_val_scaled.values, n_components=9)\n",
    "    results_with_pca = train_data(X_train_pca, y_train.values, X_val_pca, y_val.values)\n",
    "    \n",
    "    print_results(results_without_pca, header=\"Without PCA\")\n",
    "    print_results(results_with_pca, header=\"With PCA (9 dimensions)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    compare_pca_vs_non_pca()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data()\n",
    "df = impute_missing_values(df)\n",
    "df, label_encoders = label_encode_columns(df, ['explicit'])\n",
    "df = drop_unnecessary_columns(df)\n",
    "df, genre_encoder = encode_target_variable(df)\n",
    "df_train, df_test, df_val = train_test_val_split(df)\n",
    "\n",
    "X_train = df_train.drop(columns=['track_genre'])\n",
    "X_test = df_test.drop(columns=['track_genre'])\n",
    "X_val = df_val.drop(columns=['track_genre'])\n",
    "\n",
    "y_train = df_train['track_genre']\n",
    "y_test = df_test['track_genre']\n",
    "y_val = df_val['track_genre']\n",
    "\n",
    "X_train_scaled, X_test_scaled, X_val_scaled = standardize(X_train, X_test, X_val, ['explicit'])\n",
    "    \n",
    "X_train_np = X_train_scaled.values\n",
    "X_test_np = X_test_scaled.values\n",
    "X_val_np = X_val_scaled.values\n",
    "y_train_np = y_train.values\n",
    "y_val_np = y_val.values\n",
    "\n",
    "pca = PCA(n_components=X_train_np.shape[1])\n",
    "\n",
    "pca.fit(X_train_np)\n",
    "\n",
    "explained_variance_ratio = pca.ret_importance()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(np.arange(1, len(explained_variance_ratio)+1), explained_variance_ratio, marker='o', linestyle='--')\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Variance Explained')\n",
    "plt.grid(True)\n",
    "plt.savefig(\"plots/9_big_scree_plot.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
