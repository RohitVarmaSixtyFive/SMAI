{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-02T01:04:46.180657Z",
     "iopub.status.busy": "2024-11-02T01:04:46.180152Z",
     "iopub.status.idle": "2024-11-02T01:04:46.191243Z",
     "shell.execute_reply": "2024-11-02T01:04:46.190316Z",
     "shell.execute_reply.started": "2024-11-02T01:04:46.180624Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/doublemnist/double_mnist\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "data_path = os.path.join(os.getcwd(), '/kaggle/input/doublemnist/double_mnist')\n",
    "\n",
    "print(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T01:04:46.194108Z",
     "iopub.status.busy": "2024-11-02T01:04:46.193811Z",
     "iopub.status.idle": "2024-11-02T01:05:42.657428Z",
     "shell.execute_reply": "2024-11-02T01:05:42.656284Z",
     "shell.execute_reply.started": "2024-11-02T01:04:46.194069Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['val', 'test', 'train']\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Train set size: 12600 images\n",
      "Validation set size: 3000 images\n",
      "Test set size: 4600 images\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "data_path = os.path.join(os.getcwd(), '/kaggle/input/doublemnist/double_mnist')\n",
    "\n",
    "print(os.listdir('/kaggle/input/doublemnist/double_mnist'))\n",
    "\n",
    "def load_mnist_data(data_path):\n",
    "    \n",
    "    def one_hot_encode(label_str):\n",
    "        one_hot = np.zeros(33)\n",
    "        \n",
    "        for i in range(3):  \n",
    "            start_index = i * 11\n",
    "            if i < len(label_str):\n",
    "                digit = int(label_str[i])\n",
    "                one_hot[start_index + digit + 1] = 1  # Presence of a digit\n",
    "            else:\n",
    "                one_hot[start_index] = 1  # Absence of a digit\n",
    "\n",
    "        return one_hot\n",
    "    \n",
    "    def load_images_from_folder(folder):\n",
    "        images = []\n",
    "        labels = []\n",
    "        for foldername in sorted(os.listdir(folder)):\n",
    "            subfolder_path = os.path.join(folder, foldername)\n",
    "            for filename in sorted(os.listdir(subfolder_path)):\n",
    "                if filename.endswith('.png'):\n",
    "                    file_path = os.path.join(subfolder_path, filename)\n",
    "                    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "                    images.append(img)\n",
    "                    one_hot_label = one_hot_encode(foldername)\n",
    "                    labels.append(one_hot_label)\n",
    "                    \n",
    "        return images, labels\n",
    "\n",
    "    train_images, train_labels = load_images_from_folder(os.path.join(data_path, 'train'))\n",
    "    val_images, val_labels = load_images_from_folder(os.path.join(data_path, 'val'))\n",
    "    test_images, test_labels = load_images_from_folder(os.path.join(data_path, 'test'))\n",
    "    print(train_labels[0])\n",
    "    train_data = list(zip(train_images, train_labels))\n",
    "    val_data = list(zip(val_images, val_labels))\n",
    "    test_data = list(zip(test_images, test_labels))\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "train_data, val_data, test_data = load_mnist_data(data_path)\n",
    "\n",
    "print(f\"Train set size: {len(train_data)} images\")\n",
    "print(f\"Validation set size: {len(val_data)} images\")\n",
    "print(f\"Test set size: {len(test_data)} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T01:05:42.659782Z",
     "iopub.status.busy": "2024-11-02T01:05:42.659400Z",
     "iopub.status.idle": "2024-11-02T01:06:04.298098Z",
     "shell.execute_reply": "2024-11-02T01:06:04.295655Z",
     "shell.execute_reply.started": "2024-11-02T01:05:42.659741Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Dataset sizes:\n",
      "Train loader: 12600 images, 394 batches\n",
      "Validation loader: 3000 images, 94 batches\n",
      "Test loader: 4600 images, 144 batches\n",
      "\n",
      "Batch shapes:\n",
      "Images: torch.Size([32, 1, 128, 128])\n",
      "Labels: torch.Size([32, 33])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform if transform is not None else self.default_transform()\n",
    "    \n",
    "    def default_transform(self):\n",
    "        return transforms.Compose([\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.data[idx]\n",
    "        \n",
    "        # Convert to torch tensor and normalize to [0, 1]\n",
    "        image = torch.FloatTensor(image).unsqueeze(0) / 255.0\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "def create_dataloaders(data_path, batch_size=32, num_workers=4):\n",
    "    \"\"\"\n",
    "    Create train, validation and test dataloaders\n",
    "    \"\"\"\n",
    "    # Load the data\n",
    "    train_data, val_data, test_data = load_mnist_data(data_path)\n",
    "    \n",
    "    # Define transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "        # You could add more transforms here if needed:\n",
    "        # transforms.RandomRotation(10),\n",
    "        # transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    ])\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = MNISTDataset(train_data, transform=transform)\n",
    "    val_dataset = MNISTDataset(val_data, transform=transform)\n",
    "    test_dataset = MNISTDataset(test_data, transform=transform)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def create_dataloaders(data_path, batch_size=32, num_workers=4):\n",
    "    \"\"\"\n",
    "    Create train, validation and test dataloaders\n",
    "    \"\"\"\n",
    "    # Load the data\n",
    "    train_data, val_data, test_data = load_mnist_data(data_path)\n",
    "    \n",
    "    # Define transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "        # You could add more transforms here if needed:\n",
    "        # transforms.RandomRotation(10),\n",
    "        # transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    ])\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = MNISTDataset(train_data, transform=transform)\n",
    "    val_dataset = MNISTDataset(val_data, transform=transform)\n",
    "    test_dataset = MNISTDataset(test_data, transform=transform)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "data_path = os.path.join(os.getcwd(), '/kaggle/input/doublemnist/double_mnist')\n",
    "\n",
    "train_loader, val_loader, test_loader = create_dataloaders(\n",
    "    data_path,\n",
    "    batch_size=32,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"Train loader: {len(train_loader.dataset)} images, {len(train_loader)} batches\")\n",
    "print(f\"Validation loader: {len(val_loader.dataset)} images, {len(val_loader)} batches\")\n",
    "print(f\"Test loader: {len(test_loader.dataset)} images, {len(test_loader)} batches\")\n",
    "\n",
    "for images, labels in train_loader:\n",
    "#         print(images[0])\n",
    "    print(f\"\\nBatch shapes:\")\n",
    "    print(f\"Images: {images.shape}\")\n",
    "    print(f\"Labels: {labels.shape}\") \n",
    "    break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T01:06:04.301161Z",
     "iopub.status.busy": "2024-11-02T01:06:04.300594Z",
     "iopub.status.idle": "2024-11-02T01:06:04.872031Z",
     "shell.execute_reply": "2024-11-02T01:06:04.871119Z",
     "shell.execute_reply.started": "2024-11-02T01:06:04.301110Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_images_with_labels(data_loader, num_images=10):\n",
    "\n",
    "    images, labels = next(iter(data_loader))\n",
    "    \n",
    "    images = images[:num_images].squeeze().numpy()\n",
    "    labels = labels[:num_images].numpy()\n",
    "\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(15, 3))\n",
    "    for i in range(num_images):\n",
    "        ax = axes[i]\n",
    "        ax.imshow(images[i], cmap='gray')\n",
    "        ax.set_title(f\"Label: {labels[i]}\")\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "plot_images_with_labels(train_loader, num_images=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 The Multi-Label CNN implementation\n",
    "\n",
    "The changes are mainly the loss which function which changes to BCEwithLogitsLoss and an additional sigmoid layer which takes care of outputing probabilites for thresholding at 0.5 to classify into that digit.(So yes it requires final activation layer after the Linear layer just like the MLP in the last assignment). I have used sigmoid because its between 0 and 1 and its a good activation to ouput probabilites due to its shape between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T01:22:35.213439Z",
     "iopub.status.busy": "2024-11-02T01:22:35.213003Z",
     "iopub.status.idle": "2024-11-02T01:25:52.192033Z",
     "shell.execute_reply": "2024-11-02T01:25:52.190907Z",
     "shell.execute_reply.started": "2024-11-02T01:22:35.213397Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 0.2259, Val Loss: 0.2261\n",
      "Epoch [2/20], Train Loss: 0.1888, Val Loss: 0.1993\n",
      "Epoch [3/20], Train Loss: 0.1556, Val Loss: 0.1708\n",
      "Epoch [4/20], Train Loss: 0.1275, Val Loss: 0.1507\n",
      "Epoch [5/20], Train Loss: 0.1088, Val Loss: 0.1464\n",
      "Epoch [6/20], Train Loss: 0.0952, Val Loss: 0.1347\n",
      "Epoch [7/20], Train Loss: 0.0838, Val Loss: 0.1261\n",
      "Epoch [8/20], Train Loss: 0.0732, Val Loss: 0.1292\n",
      "Epoch [9/20], Train Loss: 0.0653, Val Loss: 0.1247\n",
      "Epoch [10/20], Train Loss: 0.0591, Val Loss: 0.1288\n",
      "Epoch [11/20], Train Loss: 0.0543, Val Loss: 0.1240\n",
      "Epoch [12/20], Train Loss: 0.0501, Val Loss: 0.1248\n",
      "Epoch [13/20], Train Loss: 0.0464, Val Loss: 0.1224\n",
      "Epoch [14/20], Train Loss: 0.0438, Val Loss: 0.1319\n",
      "Epoch [15/20], Train Loss: 0.0413, Val Loss: 0.1254\n",
      "Epoch [16/20], Train Loss: 0.0394, Val Loss: 0.1331\n",
      "Epoch [17/20], Train Loss: 0.0376, Val Loss: 0.1337\n",
      "Epoch [18/20], Train Loss: 0.0358, Val Loss: 0.1323\n",
      "Epoch [19/20], Train Loss: 0.0353, Val Loss: 0.1377\n",
      "Epoch [20/20], Train Loss: 0.0332, Val Loss: 0.1412\n",
      "{'hamming_score': 0.9704545454545455, 'exact_match_accuracy': 0.315}\n",
      "Final Metrics after training:\n",
      "Hamming score: 0.9705\n",
      "Exact match accuracy: 0.3150\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, hamming_loss\n",
    "import numpy as np\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, learning_rate=0.001, dropout_rate=0.2, num_conv_layers=3, optimizer_name='adam', num_classes=33):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.num_classes = num_classes  \n",
    "        self.learning_rate = learning_rate\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.num_conv_layers = num_conv_layers\n",
    "        self.optimizer_name = optimizer_name \n",
    "        self.current_size = 128\n",
    "\n",
    "        layers = []\n",
    "        in_channels = 1  \n",
    "        out_channels = 33\n",
    "\n",
    "        for _ in range(num_conv_layers):\n",
    "            layers += [\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ]\n",
    "            in_channels = out_channels\n",
    "            out_channels *= 2\n",
    "            self.current_size = self.current_size // 2\n",
    "\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "\n",
    "        self.flat_features = in_channels * (self.current_size ** 2)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.flat_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, self.num_classes) \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        return self.fc(x)\n",
    "\n",
    "    def compile_model(self):\n",
    "        if self.optimizer_name == 'adam':\n",
    "            return optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        elif self.optimizer_name == 'sgd':\n",
    "            return optim.SGD(self.parameters(), lr=self.learning_rate)\n",
    "        else:\n",
    "            raise ValueError(\"Optimizer not supported\")\n",
    "\n",
    "    def train_model(self, train_loader, val_loader, num_epochs=20, device='cpu'):\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        optimizer = self.compile_model()\n",
    "        self.to(device)\n",
    "\n",
    "        train_losses, val_losses = [], []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            self.train()\n",
    "            epoch_train_loss = 0.0\n",
    "\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device).float()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_train_loss += loss.item()\n",
    "\n",
    "            # Validation phase\n",
    "            self.eval()\n",
    "            epoch_val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_loader:\n",
    "                    images, labels = images.to(device), labels.to(device).float()\n",
    "                    outputs = self(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    epoch_val_loss += loss.item()\n",
    "\n",
    "            avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "            avg_val_loss = epoch_val_loss / len(val_loader)\n",
    "            train_losses.append(avg_train_loss)\n",
    "            val_losses.append(avg_val_loss)\n",
    "\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "        # Final metrics after all epochs\n",
    "        final_metrics = self.evaluate_metrics(val_loader, device)\n",
    "        return final_metrics\n",
    "\n",
    "    def evaluate_metrics(self, data_loader, device):\n",
    "        self.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in data_loader:\n",
    "                images, labels = images.to(device), labels.to(device).float()\n",
    "                outputs = self(images)\n",
    "\n",
    "                # Apply sigmoid and threshold\n",
    "                probabilities = torch.sigmoid(outputs)\n",
    "                predictions = (probabilities > 0.5).int()  # Threshold at 0.5\n",
    "                all_preds.extend(predictions.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Calculate Hamming score\n",
    "        hamming = 1 - hamming_loss(all_labels, all_preds)  # 1 - hamming_loss to get the score\n",
    "\n",
    "        # Calculate Exact Match Accuracy (Strict accuracy)\n",
    "        exact_match_accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "        return {\n",
    "            'hamming_score': hamming,\n",
    "            'exact_match_accuracy': exact_match_accuracy\n",
    "        }\n",
    "\n",
    "# Usage\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)\n",
    "\n",
    "# Assuming train_loader and val_loader are defined\n",
    "metrics = model.train_model(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device\n",
    ")\n",
    "print(metrics)\n",
    "# Display the final metrics\n",
    "print(\"Final Metrics after training:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric.replace('_', ' ').capitalize()}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T01:26:05.066156Z",
     "iopub.status.busy": "2024-11-02T01:26:05.065805Z",
     "iopub.status.idle": "2024-11-02T01:26:06.318978Z",
     "shell.execute_reply": "2024-11-02T01:26:06.317568Z",
     "shell.execute_reply.started": "2024-11-02T01:26:05.066117Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hamming_score': 0.9688010540184453,\n",
       " 'exact_match_accuracy': 0.22782608695652173}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_metrics(test_loader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T01:13:15.341304Z",
     "iopub.status.busy": "2024-11-02T01:13:15.340051Z",
     "iopub.status.idle": "2024-11-02T01:13:17.891920Z",
     "shell.execute_reply": "2024-11-02T01:13:17.891079Z",
     "shell.execute_reply.started": "2024-11-02T01:13:15.341260Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "my_secret = user_secrets.get_secret(\"wandb_api_key\") \n",
    "\n",
    "wandb.login(key=my_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Hyperparameter Tuning\n",
    "The best performing model is the num_conv_layer = 3,learning_rate = 0.001,dropout_rate =0.2,epochs = 20,adam optimizer with a hammming output of 0.97 and exact match accuracy being 0.308\n",
    "\n",
    "The training and validation loss plots are logged into wandb and the plot for the best loss graphs is below\n",
    "\n",
    "![image](figures/image%20copy%207.png)\n",
    "\n",
    "Trainig and validation lossfor the best configuration\n",
    "\n",
    "![image](figures/image%20copy%208.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T01:42:39.038015Z",
     "iopub.status.busy": "2024-11-02T01:42:39.037624Z",
     "iopub.status.idle": "2024-11-02T02:33:48.817507Z",
     "shell.execute_reply": "2024-11-02T02:33:48.816541Z",
     "shell.execute_reply.started": "2024-11-02T01:42:39.037975Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: awranga0\n",
      "Sweep URL: https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 935q26rd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_conv_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c4d4f8c4bd4ef9b7db3598c628a5ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112647344442747, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241102_014240-935q26rd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/935q26rd' target=\"_blank\">devout-sweep-1</a></strong> to <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/935q26rd' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/935q26rd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Train Loss: 0.2324, Val Loss: 0.2317\n",
      "Epoch [2/15], Train Loss: 0.1993, Val Loss: 0.2190\n",
      "Epoch [3/15], Train Loss: 0.1904, Val Loss: 0.2179\n",
      "Epoch [4/15], Train Loss: 0.1763, Val Loss: 0.2043\n",
      "Epoch [5/15], Train Loss: 0.1630, Val Loss: 0.2018\n",
      "Epoch [6/15], Train Loss: 0.1538, Val Loss: 0.1952\n",
      "Epoch [7/15], Train Loss: 0.1419, Val Loss: 0.1944\n",
      "Epoch [8/15], Train Loss: 0.1284, Val Loss: 0.1939\n",
      "Epoch [9/15], Train Loss: 0.1150, Val Loss: 0.1901\n",
      "Epoch [10/15], Train Loss: 0.1039, Val Loss: 0.1957\n",
      "Epoch [11/15], Train Loss: 0.0940, Val Loss: 0.1942\n",
      "Epoch [12/15], Train Loss: 0.0853, Val Loss: 0.2055\n",
      "Epoch [13/15], Train Loss: 0.0783, Val Loss: 0.2111\n",
      "Epoch [14/15], Train Loss: 0.0720, Val Loss: 0.2212\n",
      "Epoch [15/15], Train Loss: 0.0673, Val Loss: 0.2240\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.041 MB of 0.041 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>▁▃█▁▃▃▆█▆█▃▆█▁▃█▁▃▆█▃▆█▁▃▆█▁▃▆▃▆█▃▆▁▆▁▃█</td></tr><tr><td>batch_loss</td><td>█▃▂▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>exact_match_accuracy</td><td>▁▅▅▅▅▆▆▆▆▇▇█▇▇▇</td></tr><tr><td>final_exact_match_accuracy</td><td>▁</td></tr><tr><td>final_hamming_score</td><td>▁</td></tr><tr><td>final_train_accuracy</td><td>▁</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>final_val_accuracy</td><td>▁</td></tr><tr><td>final_val_loss</td><td>▁</td></tr><tr><td>hamming_score</td><td>▁▅▆▇▂▄▁▃▃▅▆▅▆▆█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▂▂▂▂▃▄▅▆▆▇██</td></tr><tr><td>train_loss</td><td>█▇▆▆▅▅▄▄▃▃▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▅▅▅▆▆▆▆▇▇█▇▇▇</td></tr><tr><td>val_loss</td><td>█▆▆▃▃▂▂▂▁▂▂▄▅▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>300</td></tr><tr><td>batch_loss</td><td>0.06441</td></tr><tr><td>epoch</td><td>15</td></tr><tr><td>exact_match_accuracy</td><td>0.04867</td></tr><tr><td>final_exact_match_accuracy</td><td>0.04867</td></tr><tr><td>final_hamming_score</td><td>0.93963</td></tr><tr><td>final_train_accuracy</td><td>0.47333</td></tr><tr><td>final_train_loss</td><td>0.06734</td></tr><tr><td>final_val_accuracy</td><td>0.04867</td></tr><tr><td>final_val_loss</td><td>0.22405</td></tr><tr><td>hamming_score</td><td>0.93963</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>train_accuracy</td><td>0.47333</td></tr><tr><td>train_loss</td><td>0.06734</td></tr><tr><td>val_accuracy</td><td>0.04867</td></tr><tr><td>val_loss</td><td>0.22405</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">devout-sweep-1</strong> at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/935q26rd' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/935q26rd</a><br/> View project at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241102_014240-935q26rd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yxyy0em6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_conv_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a1076a7f0f4d76a0d23e3c86a514e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112780166664985, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241102_014528-yxyy0em6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/yxyy0em6' target=\"_blank\">eager-sweep-2</a></strong> to <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/yxyy0em6' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/yxyy0em6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Train Loss: 0.4118, Val Loss: 0.2966\n",
      "Epoch [2/15], Train Loss: 0.2798, Val Loss: 0.2726\n",
      "Epoch [3/15], Train Loss: 0.2726, Val Loss: 0.2703\n",
      "Epoch [4/15], Train Loss: 0.2703, Val Loss: 0.2706\n",
      "Epoch [5/15], Train Loss: 0.2678, Val Loss: 0.2702\n",
      "Epoch [6/15], Train Loss: 0.2667, Val Loss: 0.2701\n",
      "Epoch [7/15], Train Loss: 0.2654, Val Loss: 0.2706\n",
      "Epoch [8/15], Train Loss: 0.2641, Val Loss: 0.2704\n",
      "Epoch [9/15], Train Loss: 0.2636, Val Loss: 0.2711\n",
      "Epoch [10/15], Train Loss: 0.2630, Val Loss: 0.2714\n",
      "Epoch [11/15], Train Loss: 0.2621, Val Loss: 0.2706\n",
      "Epoch [12/15], Train Loss: 0.2615, Val Loss: 0.2707\n",
      "Epoch [13/15], Train Loss: 0.2610, Val Loss: 0.2706\n",
      "Epoch [14/15], Train Loss: 0.2608, Val Loss: 0.2711\n",
      "Epoch [15/15], Train Loss: 0.2607, Val Loss: 0.2712\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.042 MB of 0.042 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>▁▃▆█▁▆▁▃▆█▃▆▁▃█▃▆█▁▃▁▃▆█▁▆▁▃▁▃▁▆▁▃█▃█▁▃█</td></tr><tr><td>batch_loss</td><td>█▄▄▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▂▂▂▁▂▁▂▂▂▂▂▂▁▁▂▂</td></tr><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>exact_match_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>final_exact_match_accuracy</td><td>▁</td></tr><tr><td>final_hamming_score</td><td>▁</td></tr><tr><td>final_train_accuracy</td><td>▁</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>final_val_accuracy</td><td>▁</td></tr><tr><td>final_val_loss</td><td>▁</td></tr><tr><td>hamming_score</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>300</td></tr><tr><td>batch_loss</td><td>0.26199</td></tr><tr><td>epoch</td><td>15</td></tr><tr><td>exact_match_accuracy</td><td>0</td></tr><tr><td>final_exact_match_accuracy</td><td>0</td></tr><tr><td>final_hamming_score</td><td>0.92323</td></tr><tr><td>final_train_accuracy</td><td>0</td></tr><tr><td>final_train_loss</td><td>0.26067</td></tr><tr><td>final_val_accuracy</td><td>0</td></tr><tr><td>final_val_loss</td><td>0.27119</td></tr><tr><td>hamming_score</td><td>0.92323</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>train_accuracy</td><td>0</td></tr><tr><td>train_loss</td><td>0.26067</td></tr><tr><td>val_accuracy</td><td>0</td></tr><tr><td>val_loss</td><td>0.27119</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">eager-sweep-2</strong> at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/yxyy0em6' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/yxyy0em6</a><br/> View project at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241102_014528-yxyy0em6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: z02qobkm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_conv_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1af251ee104b17aac2892d650a351c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113661255553273, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241102_014800-z02qobkm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/z02qobkm' target=\"_blank\">confused-sweep-3</a></strong> to <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/z02qobkm' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/z02qobkm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 0.2339, Val Loss: 0.2422\n",
      "Epoch [2/20], Train Loss: 0.1992, Val Loss: 0.2127\n",
      "Epoch [3/20], Train Loss: 0.1867, Val Loss: 0.2056\n",
      "Epoch [4/20], Train Loss: 0.1740, Val Loss: 0.2028\n",
      "Epoch [5/20], Train Loss: 0.1630, Val Loss: 0.1998\n",
      "Epoch [6/20], Train Loss: 0.1544, Val Loss: 0.1932\n",
      "Epoch [7/20], Train Loss: 0.1465, Val Loss: 0.1932\n",
      "Epoch [8/20], Train Loss: 0.1379, Val Loss: 0.1945\n",
      "Epoch [9/20], Train Loss: 0.1284, Val Loss: 0.1904\n",
      "Epoch [10/20], Train Loss: 0.1181, Val Loss: 0.1946\n",
      "Epoch [11/20], Train Loss: 0.1093, Val Loss: 0.1974\n",
      "Epoch [12/20], Train Loss: 0.1003, Val Loss: 0.1995\n",
      "Epoch [13/20], Train Loss: 0.0944, Val Loss: 0.2051\n",
      "Epoch [14/20], Train Loss: 0.0876, Val Loss: 0.1972\n",
      "Epoch [15/20], Train Loss: 0.0830, Val Loss: 0.2083\n",
      "Epoch [16/20], Train Loss: 0.0795, Val Loss: 0.2152\n",
      "Epoch [17/20], Train Loss: 0.0755, Val Loss: 0.2120\n",
      "Epoch [18/20], Train Loss: 0.0728, Val Loss: 0.2192\n",
      "Epoch [19/20], Train Loss: 0.0697, Val Loss: 0.2192\n",
      "Epoch [20/20], Train Loss: 0.0682, Val Loss: 0.2266\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.042 MB of 0.042 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>▁▃▆▃█▆█▃█▃██▁▃█▁▃█▁▃█▃▆▁█▆█▃▆▁██▁▃█▃█▃▆▃</td></tr><tr><td>batch_loss</td><td>███▇▆▇▇▇▆▇▆▅▄▅▄▅▅▄▅▅▃▄▃▃▃▃▃▂▃▂▂▂▂▂▁▂▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>exact_match_accuracy</td><td>▁▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇████</td></tr><tr><td>final_exact_match_accuracy</td><td>▁</td></tr><tr><td>final_hamming_score</td><td>▁</td></tr><tr><td>final_train_accuracy</td><td>▁</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>final_val_accuracy</td><td>▁</td></tr><tr><td>final_val_loss</td><td>▁</td></tr><tr><td>hamming_score</td><td>▁▄▄▄▄▂▂▃▃▃▄▆▅▇▅▆█▇█▇</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▂▂▂▂▃▃▄▄▅▆▆▇▇▇███</td></tr><tr><td>train_loss</td><td>█▇▆▅▅▅▄▄▄▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▄▃▃▂▁▁▂▁▂▂▂▃▂▃▄▄▅▅▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>300</td></tr><tr><td>batch_loss</td><td>0.06274</td></tr><tr><td>epoch</td><td>20</td></tr><tr><td>exact_match_accuracy</td><td>0.056</td></tr><tr><td>final_exact_match_accuracy</td><td>0.056</td></tr><tr><td>final_hamming_score</td><td>0.94038</td></tr><tr><td>final_train_accuracy</td><td>0.47659</td></tr><tr><td>final_train_loss</td><td>0.06816</td></tr><tr><td>final_val_accuracy</td><td>0.056</td></tr><tr><td>final_val_loss</td><td>0.22661</td></tr><tr><td>hamming_score</td><td>0.94038</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>train_accuracy</td><td>0.47659</td></tr><tr><td>train_loss</td><td>0.06816</td></tr><tr><td>val_accuracy</td><td>0.056</td></tr><tr><td>val_loss</td><td>0.22661</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">confused-sweep-3</strong> at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/z02qobkm' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/z02qobkm</a><br/> View project at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241102_014800-z02qobkm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yzdsq3l8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_conv_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba4fb006a25b4fe789e90323dd27b757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112751777778209, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241102_015138-yzdsq3l8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/yzdsq3l8' target=\"_blank\">charmed-sweep-4</a></strong> to <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/yzdsq3l8' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/yzdsq3l8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 0.3979, Val Loss: 0.2907\n",
      "Epoch [2/20], Train Loss: 0.2764, Val Loss: 0.2704\n",
      "Epoch [3/20], Train Loss: 0.2710, Val Loss: 0.2688\n",
      "Epoch [4/20], Train Loss: 0.2688, Val Loss: 0.2686\n",
      "Epoch [5/20], Train Loss: 0.2672, Val Loss: 0.2685\n",
      "Epoch [6/20], Train Loss: 0.2659, Val Loss: 0.2684\n",
      "Epoch [7/20], Train Loss: 0.2641, Val Loss: 0.2686\n",
      "Epoch [8/20], Train Loss: 0.2640, Val Loss: 0.2690\n",
      "Epoch [9/20], Train Loss: 0.2627, Val Loss: 0.2687\n",
      "Epoch [10/20], Train Loss: 0.2618, Val Loss: 0.2690\n",
      "Epoch [11/20], Train Loss: 0.2615, Val Loss: 0.2685\n",
      "Epoch [12/20], Train Loss: 0.2611, Val Loss: 0.2688\n",
      "Epoch [13/20], Train Loss: 0.2607, Val Loss: 0.2684\n",
      "Epoch [14/20], Train Loss: 0.2601, Val Loss: 0.2683\n",
      "Epoch [15/20], Train Loss: 0.2598, Val Loss: 0.2688\n",
      "Epoch [16/20], Train Loss: 0.2591, Val Loss: 0.2685\n",
      "Epoch [17/20], Train Loss: 0.2593, Val Loss: 0.2689\n",
      "Epoch [18/20], Train Loss: 0.2586, Val Loss: 0.2686\n",
      "Epoch [19/20], Train Loss: 0.2586, Val Loss: 0.2688\n",
      "Epoch [20/20], Train Loss: 0.2585, Val Loss: 0.2689\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.043 MB of 0.043 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>▁▆█▁▆█▁▃█▁█▁▃▆▃▃▆▁▃▆▁▁▆█▆▁▃▆█▁█▁▆█▁▆▃▁▆▆</td></tr><tr><td>batch_loss</td><td>█▅▂▂▂▂▂▂▁▂▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>exact_match_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>final_exact_match_accuracy</td><td>▁</td></tr><tr><td>final_hamming_score</td><td>▁</td></tr><tr><td>final_train_accuracy</td><td>▁</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>final_val_accuracy</td><td>▁</td></tr><tr><td>final_val_loss</td><td>▁</td></tr><tr><td>hamming_score</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>300</td></tr><tr><td>batch_loss</td><td>0.25231</td></tr><tr><td>epoch</td><td>20</td></tr><tr><td>exact_match_accuracy</td><td>0</td></tr><tr><td>final_exact_match_accuracy</td><td>0</td></tr><tr><td>final_hamming_score</td><td>0.92323</td></tr><tr><td>final_train_accuracy</td><td>0</td></tr><tr><td>final_train_loss</td><td>0.2585</td></tr><tr><td>final_val_accuracy</td><td>0</td></tr><tr><td>final_val_loss</td><td>0.26891</td></tr><tr><td>hamming_score</td><td>0.92323</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>train_accuracy</td><td>0</td></tr><tr><td>train_loss</td><td>0.2585</td></tr><tr><td>val_accuracy</td><td>0</td></tr><tr><td>val_loss</td><td>0.26891</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">charmed-sweep-4</strong> at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/yzdsq3l8' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/yzdsq3l8</a><br/> View project at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241102_015138-yzdsq3l8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hriuoj0y with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_conv_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6589a195459548faa0f05d8d492dd0bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112525277778534, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241102_015501-hriuoj0y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/hriuoj0y' target=\"_blank\">whole-sweep-5</a></strong> to <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/hriuoj0y' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/hriuoj0y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Train Loss: 0.2253, Val Loss: 0.2226\n",
      "Epoch [2/15], Train Loss: 0.1782, Val Loss: 0.1878\n",
      "Epoch [3/15], Train Loss: 0.1510, Val Loss: 0.1679\n",
      "Epoch [4/15], Train Loss: 0.1292, Val Loss: 0.1591\n",
      "Epoch [5/15], Train Loss: 0.1121, Val Loss: 0.1510\n",
      "Epoch [6/15], Train Loss: 0.0995, Val Loss: 0.1450\n",
      "Epoch [7/15], Train Loss: 0.0892, Val Loss: 0.1441\n",
      "Epoch [8/15], Train Loss: 0.0817, Val Loss: 0.1344\n",
      "Epoch [9/15], Train Loss: 0.0762, Val Loss: 0.1265\n",
      "Epoch [10/15], Train Loss: 0.0706, Val Loss: 0.1275\n",
      "Epoch [11/15], Train Loss: 0.0653, Val Loss: 0.1242\n",
      "Epoch [12/15], Train Loss: 0.0605, Val Loss: 0.1216\n",
      "Epoch [13/15], Train Loss: 0.0578, Val Loss: 0.1213\n",
      "Epoch [14/15], Train Loss: 0.0550, Val Loss: 0.1223\n",
      "Epoch [15/15], Train Loss: 0.0517, Val Loss: 0.1162\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.048 MB of 0.048 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>▁▃▆▁▆▃▃▆█▁▆▁▃▁▃█▁▃▆█▃▆█▁▃█▁▃█▃█▁▃▆█▃█▁▃█</td></tr><tr><td>batch_loss</td><td>█▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>exact_match_accuracy</td><td>▁▁▂▂▂▃▃▅▅▆▇▇▇▇█</td></tr><tr><td>final_exact_match_accuracy</td><td>▁</td></tr><tr><td>final_hamming_score</td><td>▁</td></tr><tr><td>final_train_accuracy</td><td>▁</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>final_val_accuracy</td><td>▁</td></tr><tr><td>final_val_loss</td><td>▁</td></tr><tr><td>hamming_score</td><td>▁▁▂▂▃▄▅▅▆▆▇▇▇██</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▂▃▄▅▅▆▆▇▇▇███</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▂▂▂▃▃▅▅▆▇▇▇▇█</td></tr><tr><td>val_loss</td><td>█▆▄▄▃▃▃▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>300</td></tr><tr><td>batch_loss</td><td>0.05102</td></tr><tr><td>epoch</td><td>15</td></tr><tr><td>exact_match_accuracy</td><td>0.236</td></tr><tr><td>final_exact_match_accuracy</td><td>0.236</td></tr><tr><td>final_hamming_score</td><td>0.96764</td></tr><tr><td>final_train_accuracy</td><td>0.57341</td></tr><tr><td>final_train_loss</td><td>0.05172</td></tr><tr><td>final_val_accuracy</td><td>0.236</td></tr><tr><td>final_val_loss</td><td>0.11618</td></tr><tr><td>hamming_score</td><td>0.96764</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>train_accuracy</td><td>0.57341</td></tr><tr><td>train_loss</td><td>0.05172</td></tr><tr><td>val_accuracy</td><td>0.236</td></tr><tr><td>val_loss</td><td>0.11618</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">whole-sweep-5</strong> at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/hriuoj0y' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/hriuoj0y</a><br/> View project at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241102_015501-hriuoj0y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ytey5mph with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_conv_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6002a90a59d34e1d84e9277b7020d95a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111354031110952, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241102_015753-ytey5mph</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/ytey5mph' target=\"_blank\">giddy-sweep-6</a></strong> to <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/ytey5mph' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/ytey5mph</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Train Loss: 0.5742, Val Loss: 0.4760\n",
      "Epoch [2/15], Train Loss: 0.3056, Val Loss: 0.3008\n",
      "Epoch [3/15], Train Loss: 0.2715, Val Loss: 0.2900\n",
      "Epoch [4/15], Train Loss: 0.2677, Val Loss: 0.2885\n",
      "Epoch [5/15], Train Loss: 0.2657, Val Loss: 0.2884\n",
      "Epoch [6/15], Train Loss: 0.2650, Val Loss: 0.2890\n",
      "Epoch [7/15], Train Loss: 0.2641, Val Loss: 0.2888\n",
      "Epoch [8/15], Train Loss: 0.2634, Val Loss: 0.2889\n",
      "Epoch [9/15], Train Loss: 0.2627, Val Loss: 0.2892\n",
      "Epoch [10/15], Train Loss: 0.2620, Val Loss: 0.2889\n",
      "Epoch [11/15], Train Loss: 0.2619, Val Loss: 0.2897\n",
      "Epoch [12/15], Train Loss: 0.2608, Val Loss: 0.2898\n",
      "Epoch [13/15], Train Loss: 0.2609, Val Loss: 0.2895\n",
      "Epoch [14/15], Train Loss: 0.2604, Val Loss: 0.2903\n",
      "Epoch [15/15], Train Loss: 0.2600, Val Loss: 0.2908\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.048 MB of 0.048 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>▁▃█▁▆▃█▁▃▆▃▆█▁▆▃▆█▁▆▁▃▆█▁▆█▁▃▆▁▃▆█▁▆█▆▁▆</td></tr><tr><td>batch_loss</td><td>█▇▅▄▃▂▂▂▁▂▂▁▁▂▂▂▁▁▂▁▁▂▂▁▂▂▂▁▁▁▂▁▁▁▂▁▂▁▂▂</td></tr><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>exact_match_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>final_exact_match_accuracy</td><td>▁</td></tr><tr><td>final_hamming_score</td><td>▁</td></tr><tr><td>final_train_accuracy</td><td>▁</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>final_val_accuracy</td><td>▁</td></tr><tr><td>final_val_loss</td><td>▁</td></tr><tr><td>hamming_score</td><td>▁██████████████</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>300</td></tr><tr><td>batch_loss</td><td>0.26616</td></tr><tr><td>epoch</td><td>15</td></tr><tr><td>exact_match_accuracy</td><td>0</td></tr><tr><td>final_exact_match_accuracy</td><td>0</td></tr><tr><td>final_hamming_score</td><td>0.92323</td></tr><tr><td>final_train_accuracy</td><td>0</td></tr><tr><td>final_train_loss</td><td>0.26004</td></tr><tr><td>final_val_accuracy</td><td>0</td></tr><tr><td>final_val_loss</td><td>0.29084</td></tr><tr><td>hamming_score</td><td>0.92323</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>train_accuracy</td><td>0</td></tr><tr><td>train_loss</td><td>0.26004</td></tr><tr><td>val_accuracy</td><td>0</td></tr><tr><td>val_loss</td><td>0.29084</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">giddy-sweep-6</strong> at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/ytey5mph' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/ytey5mph</a><br/> View project at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241102_015753-ytey5mph/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p8vfj688 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_conv_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f67b8cb56c3c43698bdb7d2beda32abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112459455555128, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241102_020040-p8vfj688</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/p8vfj688' target=\"_blank\">lively-sweep-7</a></strong> to <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/p8vfj688' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/p8vfj688</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 0.2226, Val Loss: 0.2226\n",
      "Epoch [2/20], Train Loss: 0.1801, Val Loss: 0.1952\n",
      "Epoch [3/20], Train Loss: 0.1432, Val Loss: 0.1607\n",
      "Epoch [4/20], Train Loss: 0.1192, Val Loss: 0.1423\n",
      "Epoch [5/20], Train Loss: 0.0995, Val Loss: 0.1340\n",
      "Epoch [6/20], Train Loss: 0.0863, Val Loss: 0.1292\n",
      "Epoch [7/20], Train Loss: 0.0772, Val Loss: 0.1217\n",
      "Epoch [8/20], Train Loss: 0.0693, Val Loss: 0.1247\n",
      "Epoch [9/20], Train Loss: 0.0632, Val Loss: 0.1254\n",
      "Epoch [10/20], Train Loss: 0.0584, Val Loss: 0.1236\n",
      "Epoch [11/20], Train Loss: 0.0534, Val Loss: 0.1177\n",
      "Epoch [12/20], Train Loss: 0.0505, Val Loss: 0.1231\n",
      "Epoch [13/20], Train Loss: 0.0473, Val Loss: 0.1241\n",
      "Epoch [14/20], Train Loss: 0.0441, Val Loss: 0.1307\n",
      "Epoch [15/20], Train Loss: 0.0422, Val Loss: 0.1228\n",
      "Epoch [16/20], Train Loss: 0.0393, Val Loss: 0.1157\n",
      "Epoch [17/20], Train Loss: 0.0386, Val Loss: 0.1227\n",
      "Epoch [18/20], Train Loss: 0.0359, Val Loss: 0.1309\n",
      "Epoch [19/20], Train Loss: 0.0344, Val Loss: 0.1285\n",
      "Epoch [20/20], Train Loss: 0.0331, Val Loss: 0.1318\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.048 MB of 0.048 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>▁▃▁█▁▃▃▆█▁▆█▁▃▆▁▃▆█▁█▁█▃▆▆▁▃▆▃█▁▃▆▃▃▆▁▃█</td></tr><tr><td>batch_loss</td><td>█▃▃▃▂▂▂▂▂▂▂▂▂▁▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>exact_match_accuracy</td><td>▁▂▂▃▃▄▅▅▅▆▇▇▆▇█████▇</td></tr><tr><td>final_exact_match_accuracy</td><td>▁</td></tr><tr><td>final_hamming_score</td><td>▁</td></tr><tr><td>final_train_accuracy</td><td>▁</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>final_val_accuracy</td><td>▁</td></tr><tr><td>final_val_loss</td><td>▁</td></tr><tr><td>hamming_score</td><td>▁▁▂▃▅▅▆▆▇▇▇▇▇▇██████</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▂▃▄▄▅▅▆▆▇▇▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂▂▃▃▄▅▅▅▆▇▇▆▇█████▇</td></tr><tr><td>val_loss</td><td>█▆▄▃▂▂▁▂▂▂▁▁▂▂▁▁▁▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>300</td></tr><tr><td>batch_loss</td><td>0.04142</td></tr><tr><td>epoch</td><td>20</td></tr><tr><td>exact_match_accuracy</td><td>0.308</td></tr><tr><td>final_exact_match_accuracy</td><td>0.308</td></tr><tr><td>final_hamming_score</td><td>0.97058</td></tr><tr><td>final_train_accuracy</td><td>0.7069</td></tr><tr><td>final_train_loss</td><td>0.03311</td></tr><tr><td>final_val_accuracy</td><td>0.308</td></tr><tr><td>final_val_loss</td><td>0.1318</td></tr><tr><td>hamming_score</td><td>0.97058</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>train_accuracy</td><td>0.7069</td></tr><tr><td>train_loss</td><td>0.03311</td></tr><tr><td>val_accuracy</td><td>0.308</td></tr><tr><td>val_loss</td><td>0.1318</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lively-sweep-7</strong> at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/p8vfj688' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/p8vfj688</a><br/> View project at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241102_020040-p8vfj688/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9k4sea4j with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_conv_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18292caa810d4dc4ba1d10d7c43e51d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111365135556197, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241102_020429-9k4sea4j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/9k4sea4j' target=\"_blank\">golden-sweep-8</a></strong> to <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/9k4sea4j' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/9k4sea4j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 0.5702, Val Loss: 0.4692\n",
      "Epoch [2/20], Train Loss: 0.3037, Val Loss: 0.2963\n",
      "Epoch [3/20], Train Loss: 0.2710, Val Loss: 0.2841\n",
      "Epoch [4/20], Train Loss: 0.2680, Val Loss: 0.2825\n",
      "Epoch [5/20], Train Loss: 0.2670, Val Loss: 0.2826\n",
      "Epoch [6/20], Train Loss: 0.2660, Val Loss: 0.2829\n",
      "Epoch [7/20], Train Loss: 0.2646, Val Loss: 0.2828\n",
      "Epoch [8/20], Train Loss: 0.2636, Val Loss: 0.2826\n",
      "Epoch [9/20], Train Loss: 0.2626, Val Loss: 0.2826\n",
      "Epoch [10/20], Train Loss: 0.2622, Val Loss: 0.2830\n",
      "Epoch [11/20], Train Loss: 0.2616, Val Loss: 0.2830\n",
      "Epoch [12/20], Train Loss: 0.2610, Val Loss: 0.2834\n",
      "Epoch [13/20], Train Loss: 0.2609, Val Loss: 0.2830\n",
      "Epoch [14/20], Train Loss: 0.2606, Val Loss: 0.2840\n",
      "Epoch [15/20], Train Loss: 0.2599, Val Loss: 0.2842\n",
      "Epoch [16/20], Train Loss: 0.2599, Val Loss: 0.2842\n",
      "Epoch [17/20], Train Loss: 0.2594, Val Loss: 0.2833\n",
      "Epoch [18/20], Train Loss: 0.2594, Val Loss: 0.2841\n",
      "Epoch [19/20], Train Loss: 0.2589, Val Loss: 0.2843\n",
      "Epoch [20/20], Train Loss: 0.2585, Val Loss: 0.2842\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.049 MB of 0.049 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>▁▃▆▁▃█▃▆█▃▃▁▃█▆▁▆█▁▆▃▆▆▁▆▆█▃█▆▁█▁▃▆▃▆█▃▆</td></tr><tr><td>batch_loss</td><td>█▆▄▂▂▂▂▂▁▂▂▁▁▁▂▁▂▁▁▁▂▁▁▂▂▁▂▁▁▁▂▁▁▂▁▁▁▁▁▂</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>exact_match_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>final_exact_match_accuracy</td><td>▁</td></tr><tr><td>final_hamming_score</td><td>▁</td></tr><tr><td>final_train_accuracy</td><td>▁</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>final_val_accuracy</td><td>▁</td></tr><tr><td>final_val_loss</td><td>▁</td></tr><tr><td>hamming_score</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>300</td></tr><tr><td>batch_loss</td><td>0.24901</td></tr><tr><td>epoch</td><td>20</td></tr><tr><td>exact_match_accuracy</td><td>0</td></tr><tr><td>final_exact_match_accuracy</td><td>0</td></tr><tr><td>final_hamming_score</td><td>0.92323</td></tr><tr><td>final_train_accuracy</td><td>0</td></tr><tr><td>final_train_loss</td><td>0.2585</td></tr><tr><td>final_val_accuracy</td><td>0</td></tr><tr><td>final_val_loss</td><td>0.28416</td></tr><tr><td>hamming_score</td><td>0.92323</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>train_accuracy</td><td>0</td></tr><tr><td>train_loss</td><td>0.2585</td></tr><tr><td>val_accuracy</td><td>0</td></tr><tr><td>val_loss</td><td>0.28416</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">golden-sweep-8</strong> at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/9k4sea4j' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/9k4sea4j</a><br/> View project at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241102_020429-9k4sea4j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 10ss35sy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_conv_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "136f10543e414a0aa083cadf016a3f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111377186667192, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241102_020807-10ss35sy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/10ss35sy' target=\"_blank\">elated-sweep-9</a></strong> to <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/10ss35sy' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/10ss35sy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Train Loss: 0.2593, Val Loss: 0.3041\n",
      "Epoch [2/15], Train Loss: 0.2223, Val Loss: 0.2831\n",
      "Epoch [3/15], Train Loss: 0.2104, Val Loss: 0.2697\n",
      "Epoch [4/15], Train Loss: 0.2027, Val Loss: 0.2633\n",
      "Epoch [5/15], Train Loss: 0.1950, Val Loss: 0.2526\n",
      "Epoch [6/15], Train Loss: 0.1869, Val Loss: 0.2455\n",
      "Epoch [7/15], Train Loss: 0.1785, Val Loss: 0.2398\n",
      "Epoch [8/15], Train Loss: 0.1710, Val Loss: 0.2283\n",
      "Epoch [9/15], Train Loss: 0.1648, Val Loss: 0.2270\n",
      "Epoch [10/15], Train Loss: 0.1593, Val Loss: 0.2291\n",
      "Epoch [11/15], Train Loss: 0.1552, Val Loss: 0.2232\n",
      "Epoch [12/15], Train Loss: 0.1512, Val Loss: 0.2188\n",
      "Epoch [13/15], Train Loss: 0.1481, Val Loss: 0.2207\n",
      "Epoch [14/15], Train Loss: 0.1442, Val Loss: 0.2246\n",
      "Epoch [15/15], Train Loss: 0.1413, Val Loss: 0.2246\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.042 MB of 0.042 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>▁▃▆▁▃▁▃▆█▃█▁▃▆██▆█▁▃█▁▃█▁█▁▆█▁▆█▁▃▆▁▆█▁▆</td></tr><tr><td>batch_loss</td><td>█▃▂▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▁▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>exact_match_accuracy</td><td>▁▁▁▁▁██████████</td></tr><tr><td>final_exact_match_accuracy</td><td>▁</td></tr><tr><td>final_hamming_score</td><td>▁</td></tr><tr><td>final_train_accuracy</td><td>▁</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>final_val_accuracy</td><td>▁</td></tr><tr><td>final_val_loss</td><td>▁</td></tr><tr><td>hamming_score</td><td>█▆▆▃▃▂▂▃▃▁▂▂▂▁▂</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▂▂▃▄▅▅▆▆▆▇▇█</td></tr><tr><td>train_loss</td><td>█▆▅▅▄▄▃▃▂▂▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁██████████</td></tr><tr><td>val_loss</td><td>█▆▅▅▄▃▃▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>300</td></tr><tr><td>batch_loss</td><td>0.12226</td></tr><tr><td>epoch</td><td>15</td></tr><tr><td>exact_match_accuracy</td><td>0.034</td></tr><tr><td>final_exact_match_accuracy</td><td>0.034</td></tr><tr><td>final_hamming_score</td><td>0.92294</td></tr><tr><td>final_train_accuracy</td><td>0.07175</td></tr><tr><td>final_train_loss</td><td>0.14132</td></tr><tr><td>final_val_accuracy</td><td>0.034</td></tr><tr><td>final_val_loss</td><td>0.22458</td></tr><tr><td>hamming_score</td><td>0.92294</td></tr><tr><td>learning_rate</td><td>0.0001</td></tr><tr><td>train_accuracy</td><td>0.07175</td></tr><tr><td>train_loss</td><td>0.14132</td></tr><tr><td>val_accuracy</td><td>0.034</td></tr><tr><td>val_loss</td><td>0.22458</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">elated-sweep-9</strong> at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/10ss35sy' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/10ss35sy</a><br/> View project at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241102_020807-10ss35sy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4k6s7lxs with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_conv_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a817638931d4ffa9570e5ea26469a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112784177779151, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241102_021054-4k6s7lxs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/4k6s7lxs' target=\"_blank\">chocolate-sweep-10</a></strong> to <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/4k6s7lxs' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/4k6s7lxs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Train Loss: 0.6465, Val Loss: 0.6261\n",
      "Epoch [2/15], Train Loss: 0.5558, Val Loss: 0.5582\n",
      "Epoch [3/15], Train Loss: 0.4806, Val Loss: 0.4942\n",
      "Epoch [4/15], Train Loss: 0.4202, Val Loss: 0.4374\n",
      "Epoch [5/15], Train Loss: 0.3733, Val Loss: 0.3905\n",
      "Epoch [6/15], Train Loss: 0.3401, Val Loss: 0.3547\n",
      "Epoch [7/15], Train Loss: 0.3173, Val Loss: 0.3291\n",
      "Epoch [8/15], Train Loss: 0.3027, Val Loss: 0.3113\n",
      "Epoch [9/15], Train Loss: 0.2940, Val Loss: 0.2993\n",
      "Epoch [10/15], Train Loss: 0.2884, Val Loss: 0.2910\n",
      "Epoch [11/15], Train Loss: 0.2840, Val Loss: 0.2851\n",
      "Epoch [12/15], Train Loss: 0.2820, Val Loss: 0.2811\n",
      "Epoch [13/15], Train Loss: 0.2805, Val Loss: 0.2781\n",
      "Epoch [14/15], Train Loss: 0.2785, Val Loss: 0.2759\n",
      "Epoch [15/15], Train Loss: 0.2778, Val Loss: 0.2742\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.042 MB of 0.042 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>▃▆█▁▃▃█▁▃▆▃▆█▁▃█▁▃▆█▆█▃▆█▃▆█▁▃▃▆▁▃▆▁▆█▁▆</td></tr><tr><td>batch_loss</td><td>██▇▇▆▅▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▂▁▂▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>exact_match_accuracy</td><td>▁█▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>final_exact_match_accuracy</td><td>▁</td></tr><tr><td>final_hamming_score</td><td>▁</td></tr><tr><td>final_train_accuracy</td><td>▁</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>final_val_accuracy</td><td>▁</td></tr><tr><td>final_val_loss</td><td>▁</td></tr><tr><td>hamming_score</td><td>▁▅█████████████</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▃█▇▅▃▇▃▃▁▅▇▂▃▇</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁█▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▅▄▃▃▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>300</td></tr><tr><td>batch_loss</td><td>0.26434</td></tr><tr><td>epoch</td><td>15</td></tr><tr><td>exact_match_accuracy</td><td>0</td></tr><tr><td>final_exact_match_accuracy</td><td>0</td></tr><tr><td>final_hamming_score</td><td>0.92323</td></tr><tr><td>final_train_accuracy</td><td>0.0004</td></tr><tr><td>final_train_loss</td><td>0.27778</td></tr><tr><td>final_val_accuracy</td><td>0</td></tr><tr><td>final_val_loss</td><td>0.2742</td></tr><tr><td>hamming_score</td><td>0.92323</td></tr><tr><td>learning_rate</td><td>0.0001</td></tr><tr><td>train_accuracy</td><td>0.0004</td></tr><tr><td>train_loss</td><td>0.27778</td></tr><tr><td>val_accuracy</td><td>0</td></tr><tr><td>val_loss</td><td>0.2742</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">chocolate-sweep-10</strong> at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/4k6s7lxs' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/4k6s7lxs</a><br/> View project at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241102_021054-4k6s7lxs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ukhnyiuf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_conv_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8509aaf834cc4504974095fd21c2a183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112653622219821, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241102_021337-ukhnyiuf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/ukhnyiuf' target=\"_blank\">sage-sweep-11</a></strong> to <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/ukhnyiuf' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/ukhnyiuf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 0.2667, Val Loss: 0.2784\n",
      "Epoch [2/20], Train Loss: 0.2226, Val Loss: 0.2779\n",
      "Epoch [3/20], Train Loss: 0.2108, Val Loss: 0.2623\n",
      "Epoch [4/20], Train Loss: 0.2020, Val Loss: 0.2502\n",
      "Epoch [5/20], Train Loss: 0.1921, Val Loss: 0.2376\n",
      "Epoch [6/20], Train Loss: 0.1831, Val Loss: 0.2256\n",
      "Epoch [7/20], Train Loss: 0.1751, Val Loss: 0.2180\n",
      "Epoch [8/20], Train Loss: 0.1675, Val Loss: 0.2152\n",
      "Epoch [9/20], Train Loss: 0.1617, Val Loss: 0.2152\n",
      "Epoch [10/20], Train Loss: 0.1574, Val Loss: 0.2080\n",
      "Epoch [11/20], Train Loss: 0.1533, Val Loss: 0.2104\n",
      "Epoch [12/20], Train Loss: 0.1501, Val Loss: 0.2100\n",
      "Epoch [13/20], Train Loss: 0.1466, Val Loss: 0.2069\n",
      "Epoch [14/20], Train Loss: 0.1434, Val Loss: 0.2053\n",
      "Epoch [15/20], Train Loss: 0.1395, Val Loss: 0.2051\n",
      "Epoch [16/20], Train Loss: 0.1363, Val Loss: 0.2092\n",
      "Epoch [17/20], Train Loss: 0.1328, Val Loss: 0.2092\n",
      "Epoch [18/20], Train Loss: 0.1292, Val Loss: 0.2114\n",
      "Epoch [19/20], Train Loss: 0.1252, Val Loss: 0.2102\n",
      "Epoch [20/20], Train Loss: 0.1219, Val Loss: 0.2130\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.042 MB of 0.042 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>▁▃█▃▆▁█▁▆█▃▁█▆█▃▆█▃▆▁▃▁▃▁█▁█▁▃▃█▃▆█▃▁▃▆▆</td></tr><tr><td>batch_loss</td><td>█▇▆▅▆▅▆▅▅▃▄▅▄▄▄▃▃▄▃▂▂▃▃▂▃▃▂▃▂▃▂▁▂▂▁▂▁▁▂▁</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>exact_match_accuracy</td><td>▁▁▁▁▁▁██████████████</td></tr><tr><td>final_exact_match_accuracy</td><td>▁</td></tr><tr><td>final_hamming_score</td><td>▁</td></tr><tr><td>final_train_accuracy</td><td>▁</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>final_val_accuracy</td><td>▁</td></tr><tr><td>final_val_loss</td><td>▁</td></tr><tr><td>hamming_score</td><td>█▇▇█▆▅▇▄▁▄▂▂▃▄▄▃▃▃▄▃</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▂▂▂▃▃▄▄▄▄▅▅▆▆▇▇█</td></tr><tr><td>train_loss</td><td>█▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁▁██████████████</td></tr><tr><td>val_loss</td><td>██▆▅▄▃▂▂▂▁▂▁▁▁▁▁▁▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>300</td></tr><tr><td>batch_loss</td><td>0.11977</td></tr><tr><td>epoch</td><td>20</td></tr><tr><td>exact_match_accuracy</td><td>0.035</td></tr><tr><td>final_exact_match_accuracy</td><td>0.035</td></tr><tr><td>final_hamming_score</td><td>0.92974</td></tr><tr><td>final_train_accuracy</td><td>0.12468</td></tr><tr><td>final_train_loss</td><td>0.1219</td></tr><tr><td>final_val_accuracy</td><td>0.035</td></tr><tr><td>final_val_loss</td><td>0.21297</td></tr><tr><td>hamming_score</td><td>0.92974</td></tr><tr><td>learning_rate</td><td>0.0001</td></tr><tr><td>train_accuracy</td><td>0.12468</td></tr><tr><td>train_loss</td><td>0.1219</td></tr><tr><td>val_accuracy</td><td>0.035</td></tr><tr><td>val_loss</td><td>0.21297</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sage-sweep-11</strong> at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/ukhnyiuf' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/ukhnyiuf</a><br/> View project at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241102_021337-ukhnyiuf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zf9v9xww with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_conv_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de09369467f4aa38fd140be12fa70a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113496988885647, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241102_021720-zf9v9xww</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/zf9v9xww' target=\"_blank\">stellar-sweep-12</a></strong> to <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/zf9v9xww' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/zf9v9xww</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 0.6308, Val Loss: 0.6101\n",
      "Epoch [2/20], Train Loss: 0.5415, Val Loss: 0.5403\n",
      "Epoch [3/20], Train Loss: 0.4677, Val Loss: 0.4753\n",
      "Epoch [4/20], Train Loss: 0.4077, Val Loss: 0.4193\n",
      "Epoch [5/20], Train Loss: 0.3631, Val Loss: 0.3754\n",
      "Epoch [6/20], Train Loss: 0.3326, Val Loss: 0.3434\n",
      "Epoch [7/20], Train Loss: 0.3127, Val Loss: 0.3212\n",
      "Epoch [8/20], Train Loss: 0.3007, Val Loss: 0.3061\n",
      "Epoch [9/20], Train Loss: 0.2921, Val Loss: 0.2959\n",
      "Epoch [10/20], Train Loss: 0.2873, Val Loss: 0.2888\n",
      "Epoch [11/20], Train Loss: 0.2840, Val Loss: 0.2838\n",
      "Epoch [12/20], Train Loss: 0.2804, Val Loss: 0.2803\n",
      "Epoch [13/20], Train Loss: 0.2791, Val Loss: 0.2777\n",
      "Epoch [14/20], Train Loss: 0.2774, Val Loss: 0.2760\n",
      "Epoch [15/20], Train Loss: 0.2769, Val Loss: 0.2747\n",
      "Epoch [16/20], Train Loss: 0.2751, Val Loss: 0.2737\n",
      "Epoch [17/20], Train Loss: 0.2748, Val Loss: 0.2729\n",
      "Epoch [18/20], Train Loss: 0.2734, Val Loss: 0.2722\n",
      "Epoch [19/20], Train Loss: 0.2738, Val Loss: 0.2717\n",
      "Epoch [20/20], Train Loss: 0.2729, Val Loss: 0.2712\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.043 MB of 0.043 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>▁▃▆█▁▆█▃▆▃▁▃█▃▆▁▃▁▆▁▁▆█▁▃█▁▃█▃▁▃▆█▆▁▃▆▃█</td></tr><tr><td>batch_loss</td><td>██▇▆▅▄▄▄▄▃▃▂▂▂▂▂▂▂▂▂▁▂▂▂▁▂▁▁▁▁▁▁▂▁▂▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>exact_match_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>final_exact_match_accuracy</td><td>▁</td></tr><tr><td>final_hamming_score</td><td>▁</td></tr><tr><td>final_train_accuracy</td><td>▁</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>final_val_accuracy</td><td>▁</td></tr><tr><td>final_val_loss</td><td>▁</td></tr><tr><td>hamming_score</td><td>▁▃▅█████████████████</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁█▅▁▅▁▁▁▁▅▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▅▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>300</td></tr><tr><td>batch_loss</td><td>0.26106</td></tr><tr><td>epoch</td><td>20</td></tr><tr><td>exact_match_accuracy</td><td>0</td></tr><tr><td>final_exact_match_accuracy</td><td>0</td></tr><tr><td>final_hamming_score</td><td>0.92323</td></tr><tr><td>final_train_accuracy</td><td>0</td></tr><tr><td>final_train_loss</td><td>0.27287</td></tr><tr><td>final_val_accuracy</td><td>0</td></tr><tr><td>final_val_loss</td><td>0.27124</td></tr><tr><td>hamming_score</td><td>0.92323</td></tr><tr><td>learning_rate</td><td>0.0001</td></tr><tr><td>train_accuracy</td><td>0</td></tr><tr><td>train_loss</td><td>0.27287</td></tr><tr><td>val_accuracy</td><td>0</td></tr><tr><td>val_loss</td><td>0.27124</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stellar-sweep-12</strong> at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/zf9v9xww' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/zf9v9xww</a><br/> View project at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241102_021720-zf9v9xww/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kotjsfko with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_conv_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acfd169ef6344ec1910fe5fe4fd7093f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111249214444696, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241102_022043-kotjsfko</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/kotjsfko' target=\"_blank\">fearless-sweep-13</a></strong> to <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/kotjsfko' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/kotjsfko</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Train Loss: 0.2642, Val Loss: 0.2877\n",
      "Epoch [2/15], Train Loss: 0.2201, Val Loss: 0.2619\n",
      "Epoch [3/15], Train Loss: 0.2088, Val Loss: 0.2595\n",
      "Epoch [4/15], Train Loss: 0.2015, Val Loss: 0.2562\n",
      "Epoch [5/15], Train Loss: 0.1929, Val Loss: 0.2414\n",
      "Epoch [6/15], Train Loss: 0.1800, Val Loss: 0.2352\n",
      "Epoch [7/15], Train Loss: 0.1679, Val Loss: 0.2222\n",
      "Epoch [8/15], Train Loss: 0.1582, Val Loss: 0.2119\n",
      "Epoch [9/15], Train Loss: 0.1482, Val Loss: 0.2086\n",
      "Epoch [10/15], Train Loss: 0.1391, Val Loss: 0.1967\n",
      "Epoch [11/15], Train Loss: 0.1308, Val Loss: 0.1920\n",
      "Epoch [12/15], Train Loss: 0.1220, Val Loss: 0.1797\n",
      "Epoch [13/15], Train Loss: 0.1154, Val Loss: 0.1820\n",
      "Epoch [14/15], Train Loss: 0.1094, Val Loss: 0.1745\n",
      "Epoch [15/15], Train Loss: 0.1035, Val Loss: 0.1745\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.048 MB of 0.048 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>▁▃▆█▁█▁▃█▁█▁▆▁▃▁▃▆█▁▆█▁▃▆▁▃▆▃█▃▆▁▆▁▆█▁▃█</td></tr><tr><td>batch_loss</td><td>█▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>exact_match_accuracy</td><td>▁▁▁▅▅▅▅▅▅▅▅▆▆██</td></tr><tr><td>final_exact_match_accuracy</td><td>▁</td></tr><tr><td>final_hamming_score</td><td>▁</td></tr><tr><td>final_train_accuracy</td><td>▁</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>final_val_accuracy</td><td>▁</td></tr><tr><td>final_val_loss</td><td>▁</td></tr><tr><td>hamming_score</td><td>▆▆▅▃▃▁▃▄▃▅▅▇▆██</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▂▂▂▂▂▃▃▄▅▆▇█</td></tr><tr><td>train_loss</td><td>█▆▆▅▅▄▄▃▃▃▂▂▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▅▅▅▅▅▅▅▅▆▆██</td></tr><tr><td>val_loss</td><td>█▆▆▆▅▅▄▃▃▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>300</td></tr><tr><td>batch_loss</td><td>0.10645</td></tr><tr><td>epoch</td><td>15</td></tr><tr><td>exact_match_accuracy</td><td>0.061</td></tr><tr><td>final_exact_match_accuracy</td><td>0.061</td></tr><tr><td>final_hamming_score</td><td>0.93877</td></tr><tr><td>final_train_accuracy</td><td>0.23175</td></tr><tr><td>final_train_loss</td><td>0.10353</td></tr><tr><td>final_val_accuracy</td><td>0.061</td></tr><tr><td>final_val_loss</td><td>0.17448</td></tr><tr><td>hamming_score</td><td>0.93877</td></tr><tr><td>learning_rate</td><td>0.0001</td></tr><tr><td>train_accuracy</td><td>0.23175</td></tr><tr><td>train_loss</td><td>0.10353</td></tr><tr><td>val_accuracy</td><td>0.061</td></tr><tr><td>val_loss</td><td>0.17448</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fearless-sweep-13</strong> at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/kotjsfko' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/kotjsfko</a><br/> View project at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241102_022043-kotjsfko/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vuuo18kd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_conv_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d464b571512c4c26a865cf7ab1901013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113442611106923, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241102_022335-vuuo18kd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/vuuo18kd' target=\"_blank\">efficient-sweep-14</a></strong> to <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/vuuo18kd' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/vuuo18kd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Train Loss: 0.6804, Val Loss: 0.6797\n",
      "Epoch [2/15], Train Loss: 0.6515, Val Loss: 0.6645\n",
      "Epoch [3/15], Train Loss: 0.6219, Val Loss: 0.6461\n",
      "Epoch [4/15], Train Loss: 0.5897, Val Loss: 0.6240\n",
      "Epoch [5/15], Train Loss: 0.5550, Val Loss: 0.5973\n",
      "Epoch [6/15], Train Loss: 0.5176, Val Loss: 0.5656\n",
      "Epoch [7/15], Train Loss: 0.4784, Val Loss: 0.5297\n",
      "Epoch [8/15], Train Loss: 0.4387, Val Loss: 0.4915\n",
      "Epoch [9/15], Train Loss: 0.4026, Val Loss: 0.4538\n",
      "Epoch [10/15], Train Loss: 0.3711, Val Loss: 0.4193\n",
      "Epoch [11/15], Train Loss: 0.3466, Val Loss: 0.3900\n",
      "Epoch [12/15], Train Loss: 0.3264, Val Loss: 0.3666\n",
      "Epoch [13/15], Train Loss: 0.3124, Val Loss: 0.3486\n",
      "Epoch [14/15], Train Loss: 0.3024, Val Loss: 0.3351\n",
      "Epoch [15/15], Train Loss: 0.2952, Val Loss: 0.3250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.049 MB of 0.049 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>▁▃▆█▁▆█▁▆█▆█▁▆█▆▁▃█▁▆█▃▆█▆█▁▃▆▁▃█▁▃▁▃█▁█</td></tr><tr><td>batch_loss</td><td>████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>exact_match_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>final_exact_match_accuracy</td><td>▁</td></tr><tr><td>final_hamming_score</td><td>▁</td></tr><tr><td>final_train_accuracy</td><td>▁</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>final_val_accuracy</td><td>▁</td></tr><tr><td>final_val_loss</td><td>▁</td></tr><tr><td>hamming_score</td><td>▁▃▄▅▆▇▇▇███████</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▁██▁▁█▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▅▄▄▃▂▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>██▇▇▆▆▅▄▄▃▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>300</td></tr><tr><td>batch_loss</td><td>0.28496</td></tr><tr><td>epoch</td><td>15</td></tr><tr><td>exact_match_accuracy</td><td>0</td></tr><tr><td>final_exact_match_accuracy</td><td>0</td></tr><tr><td>final_hamming_score</td><td>0.92323</td></tr><tr><td>final_train_accuracy</td><td>0</td></tr><tr><td>final_train_loss</td><td>0.29517</td></tr><tr><td>final_val_accuracy</td><td>0</td></tr><tr><td>final_val_loss</td><td>0.32501</td></tr><tr><td>hamming_score</td><td>0.92323</td></tr><tr><td>learning_rate</td><td>0.0001</td></tr><tr><td>train_accuracy</td><td>0</td></tr><tr><td>train_loss</td><td>0.29517</td></tr><tr><td>val_accuracy</td><td>0</td></tr><tr><td>val_loss</td><td>0.32501</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">efficient-sweep-14</strong> at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/vuuo18kd' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/vuuo18kd</a><br/> View project at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241102_022335-vuuo18kd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pzwfp9tz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_conv_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f34d2d141c7c4273b46e598238171687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112811355552468, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241102_022623-pzwfp9tz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/pzwfp9tz' target=\"_blank\">driven-sweep-15</a></strong> to <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/pzwfp9tz' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/pzwfp9tz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 0.2609, Val Loss: 0.2772\n",
      "Epoch [2/20], Train Loss: 0.2183, Val Loss: 0.2634\n",
      "Epoch [3/20], Train Loss: 0.2079, Val Loss: 0.2537\n",
      "Epoch [4/20], Train Loss: 0.1998, Val Loss: 0.2465\n",
      "Epoch [5/20], Train Loss: 0.1908, Val Loss: 0.2303\n",
      "Epoch [6/20], Train Loss: 0.1803, Val Loss: 0.2249\n",
      "Epoch [7/20], Train Loss: 0.1709, Val Loss: 0.2159\n",
      "Epoch [8/20], Train Loss: 0.1609, Val Loss: 0.2125\n",
      "Epoch [9/20], Train Loss: 0.1512, Val Loss: 0.2037\n",
      "Epoch [10/20], Train Loss: 0.1415, Val Loss: 0.1974\n",
      "Epoch [11/20], Train Loss: 0.1331, Val Loss: 0.1957\n",
      "Epoch [12/20], Train Loss: 0.1250, Val Loss: 0.1937\n",
      "Epoch [13/20], Train Loss: 0.1178, Val Loss: 0.1857\n",
      "Epoch [14/20], Train Loss: 0.1119, Val Loss: 0.1901\n",
      "Epoch [15/20], Train Loss: 0.1064, Val Loss: 0.1856\n",
      "Epoch [16/20], Train Loss: 0.1014, Val Loss: 0.1745\n",
      "Epoch [17/20], Train Loss: 0.0973, Val Loss: 0.1863\n",
      "Epoch [18/20], Train Loss: 0.0936, Val Loss: 0.1799\n",
      "Epoch [19/20], Train Loss: 0.0893, Val Loss: 0.1760\n",
      "Epoch [20/20], Train Loss: 0.0861, Val Loss: 0.1777\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.048 MB of 0.048 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>▁▃▆█▁▆▁▃█▁▁█▁▆█▃▆█▃▆▃▆▁▃▆▁▃█▃▆▃▆▁▆█▃▃▁▃█</td></tr><tr><td>batch_loss</td><td>█▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>exact_match_accuracy</td><td>▁▁▁▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇██</td></tr><tr><td>final_exact_match_accuracy</td><td>▁</td></tr><tr><td>final_hamming_score</td><td>▁</td></tr><tr><td>final_train_accuracy</td><td>▁</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>final_val_accuracy</td><td>▁</td></tr><tr><td>final_val_loss</td><td>▁</td></tr><tr><td>hamming_score</td><td>▃▂▂▂▃▂▂▁▂▂▂▃▄▄▄▆▅▇██</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▂▂▂▂▂▃▃▄▄▅▆▆▇▇██</td></tr><tr><td>train_loss</td><td>█▆▆▆▅▅▄▄▄▃▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇██</td></tr><tr><td>val_loss</td><td>█▇▆▆▅▄▄▄▃▃▂▂▂▂▂▁▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>300</td></tr><tr><td>batch_loss</td><td>0.08874</td></tr><tr><td>epoch</td><td>20</td></tr><tr><td>exact_match_accuracy</td><td>0.066</td></tr><tr><td>final_exact_match_accuracy</td><td>0.066</td></tr><tr><td>final_hamming_score</td><td>0.94143</td></tr><tr><td>final_train_accuracy</td><td>0.33175</td></tr><tr><td>final_train_loss</td><td>0.08611</td></tr><tr><td>final_val_accuracy</td><td>0.066</td></tr><tr><td>final_val_loss</td><td>0.1777</td></tr><tr><td>hamming_score</td><td>0.94143</td></tr><tr><td>learning_rate</td><td>0.0001</td></tr><tr><td>train_accuracy</td><td>0.33175</td></tr><tr><td>train_loss</td><td>0.08611</td></tr><tr><td>val_accuracy</td><td>0.066</td></tr><tr><td>val_loss</td><td>0.1777</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">driven-sweep-15</strong> at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/pzwfp9tz' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/pzwfp9tz</a><br/> View project at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241102_022623-pzwfp9tz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fsp4lblj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_conv_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299af0ee2cd34eb5af1177bc0d70b30e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113498622226973, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241102_023011-fsp4lblj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/fsp4lblj' target=\"_blank\">solar-sweep-16</a></strong> to <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/sweeps/awranga0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/fsp4lblj' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/fsp4lblj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 0.6871, Val Loss: 0.6873\n",
      "Epoch [2/20], Train Loss: 0.6608, Val Loss: 0.6728\n",
      "Epoch [3/20], Train Loss: 0.6313, Val Loss: 0.6545\n",
      "Epoch [4/20], Train Loss: 0.5969, Val Loss: 0.6311\n",
      "Epoch [5/20], Train Loss: 0.5568, Val Loss: 0.6014\n",
      "Epoch [6/20], Train Loss: 0.5124, Val Loss: 0.5656\n",
      "Epoch [7/20], Train Loss: 0.4659, Val Loss: 0.5249\n",
      "Epoch [8/20], Train Loss: 0.4205, Val Loss: 0.4820\n",
      "Epoch [9/20], Train Loss: 0.3795, Val Loss: 0.4406\n",
      "Epoch [10/20], Train Loss: 0.3464, Val Loss: 0.4042\n",
      "Epoch [11/20], Train Loss: 0.3214, Val Loss: 0.3747\n",
      "Epoch [12/20], Train Loss: 0.3037, Val Loss: 0.3521\n",
      "Epoch [13/20], Train Loss: 0.2933, Val Loss: 0.3353\n",
      "Epoch [14/20], Train Loss: 0.2861, Val Loss: 0.3233\n",
      "Epoch [15/20], Train Loss: 0.2808, Val Loss: 0.3147\n",
      "Epoch [16/20], Train Loss: 0.2783, Val Loss: 0.3083\n",
      "Epoch [17/20], Train Loss: 0.2762, Val Loss: 0.3038\n",
      "Epoch [18/20], Train Loss: 0.2749, Val Loss: 0.3005\n",
      "Epoch [19/20], Train Loss: 0.2735, Val Loss: 0.2979\n",
      "Epoch [20/20], Train Loss: 0.2727, Val Loss: 0.2961\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.049 MB of 0.049 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>▆█▁▆▃▁▃█▁▃▁█▁▃▆▆▁▃▆▃▃▆█▃█▆█▃▁▆▃█▁▃▁▁▃▆██</td></tr><tr><td>batch_loss</td><td>████▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▁▂▂▁▂▂▂▁▂▁▁</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>exact_match_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>final_exact_match_accuracy</td><td>▁</td></tr><tr><td>final_hamming_score</td><td>▁</td></tr><tr><td>final_train_accuracy</td><td>▁</td></tr><tr><td>final_train_loss</td><td>▁</td></tr><tr><td>final_val_accuracy</td><td>▁</td></tr><tr><td>final_val_loss</td><td>▁</td></tr><tr><td>hamming_score</td><td>▁▄▅▆▇▇██████████████</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▂▄█▄▃▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>██▇▆▆▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>██▇▇▆▆▅▄▄▃▂▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>300</td></tr><tr><td>batch_loss</td><td>0.25071</td></tr><tr><td>epoch</td><td>20</td></tr><tr><td>exact_match_accuracy</td><td>0</td></tr><tr><td>final_exact_match_accuracy</td><td>0</td></tr><tr><td>final_hamming_score</td><td>0.92323</td></tr><tr><td>final_train_accuracy</td><td>0</td></tr><tr><td>final_train_loss</td><td>0.27273</td></tr><tr><td>final_val_accuracy</td><td>0</td></tr><tr><td>final_val_loss</td><td>0.29606</td></tr><tr><td>hamming_score</td><td>0.92323</td></tr><tr><td>learning_rate</td><td>0.0001</td></tr><tr><td>train_accuracy</td><td>0</td></tr><tr><td>train_loss</td><td>0.27273</td></tr><tr><td>val_accuracy</td><td>0</td></tr><tr><td>val_loss</td><td>0.29606</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">solar-sweep-16</strong> at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/fsp4lblj' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification/runs/fsp4lblj</a><br/> View project at: <a href='https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification' target=\"_blank\">https://wandb.ai/mjolnir65-iiit-hyderabad/CNN-Multi-Label-Classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241102_023011-fsp4lblj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "from sklearn.metrics import accuracy_score, hamming_loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, learning_rate=0.001, dropout_rate=0.2, num_conv_layers=3, optimizer_name='adam', num_classes=33):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Initialize wandb config\n",
    "        self.config = {\n",
    "            'learning_rate': learning_rate,\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'num_conv_layers': num_conv_layers,\n",
    "            'optimizer_name': optimizer_name,\n",
    "            'num_classes': num_classes\n",
    "        }\n",
    "\n",
    "        self.num_classes = num_classes  \n",
    "        self.learning_rate = learning_rate\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.num_conv_layers = num_conv_layers\n",
    "        self.optimizer_name = optimizer_name \n",
    "        self.current_size = 128\n",
    "\n",
    "        layers = []\n",
    "        in_channels = 1  \n",
    "        out_channels = 33\n",
    "\n",
    "        for _ in range(num_conv_layers):\n",
    "            layers += [\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ]\n",
    "            in_channels = out_channels\n",
    "            out_channels *= 2\n",
    "            self.current_size = self.current_size // 2\n",
    "\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "        self.flat_features = in_channels * (self.current_size ** 2)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.flat_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, self.num_classes) \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "    def compile_model(self):\n",
    "        if self.optimizer_name == 'adam':\n",
    "            return optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        elif self.optimizer_name == 'sgd':\n",
    "            return optim.SGD(self.parameters(), lr=self.learning_rate)\n",
    "        else:\n",
    "            raise ValueError(\"Optimizer not supported\")\n",
    "\n",
    "    def train_model(self, train_loader, val_loader, num_epochs=20, device='cpu'):\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        optimizer = self.compile_model()\n",
    "        self.to(device)\n",
    "\n",
    "        # Log model architecture and hyperparameters\n",
    "        wandb.watch(self, criterion, log=\"all\", log_freq=100)\n",
    "\n",
    "        train_losses, val_losses = [], []\n",
    "        train_accuracies, val_accuracies = [], []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            self.train()\n",
    "            epoch_train_loss = 0.0\n",
    "            correct_train = 0\n",
    "            total_train = 0\n",
    "\n",
    "            # Training loop\n",
    "            for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "                images, labels = images.to(device), labels.to(device).float()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_train_loss += loss.item()\n",
    "                predictions = (torch.sigmoid(outputs) > 0.5).int()\n",
    "                correct_train += (predictions == labels.int()).all(dim=1).sum().item()\n",
    "                total_train += labels.size(0)\n",
    "\n",
    "                # Log training metrics every 100 batches\n",
    "                if batch_idx % 100 == 0:\n",
    "                    wandb.log({\n",
    "                        \"batch\": batch_idx,\n",
    "                        \"batch_loss\": loss.item(),\n",
    "                    })\n",
    "\n",
    "            # Calculate training metrics\n",
    "            avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "            train_accuracy = correct_train / total_train\n",
    "            train_losses.append(avg_train_loss)\n",
    "            train_accuracies.append(train_accuracy)\n",
    "\n",
    "            # Validation phase\n",
    "            self.eval()\n",
    "            epoch_val_loss = 0.0\n",
    "            correct_val = 0\n",
    "            total_val = 0\n",
    "            val_predictions = []\n",
    "            val_true_labels = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_loader:\n",
    "                    images, labels = images.to(device), labels.to(device).float()\n",
    "                    outputs = self(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    epoch_val_loss += loss.item()\n",
    "\n",
    "                    predictions = (torch.sigmoid(outputs) > 0.5).int()\n",
    "                    correct_val += (predictions == labels.int()).all(dim=1).sum().item()\n",
    "                    total_val += labels.size(0)\n",
    "\n",
    "                    val_predictions.extend(predictions.cpu().numpy())\n",
    "                    val_true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            # Calculate validation metrics\n",
    "            avg_val_loss = epoch_val_loss / len(val_loader)\n",
    "            val_accuracy = correct_val / total_val\n",
    "            val_losses.append(avg_val_loss)\n",
    "            val_accuracies.append(val_accuracy)\n",
    "\n",
    "            # Calculate Hamming score and exact match accuracy\n",
    "            hamming_score = 1 - hamming_loss(val_true_labels, val_predictions)\n",
    "            exact_match = accuracy_score(val_true_labels, val_predictions)\n",
    "\n",
    "            # Log epoch metrics to wandb\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"train_loss\": avg_train_loss,\n",
    "                \"val_loss\": avg_val_loss,\n",
    "                \"train_accuracy\": train_accuracy,\n",
    "                \"val_accuracy\": val_accuracy,\n",
    "                \"hamming_score\": hamming_score,\n",
    "                \"exact_match_accuracy\": exact_match,\n",
    "                \"learning_rate\": self.learning_rate\n",
    "            })\n",
    "\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "        # Get final evaluation metrics\n",
    "        final_metrics = self.evaluate_metrics(val_loader, device)\n",
    "        \n",
    "        # Log final metrics to wandb\n",
    "        wandb.log({\n",
    "            \"final_train_accuracy\": train_accuracies[-1],\n",
    "            \"final_val_accuracy\": val_accuracies[-1],\n",
    "            \"final_train_loss\": train_losses[-1],\n",
    "            \"final_val_loss\": val_losses[-1],\n",
    "            \"final_hamming_score\": final_metrics['hamming_score'],\n",
    "            \"final_exact_match_accuracy\": final_metrics['exact_match_accuracy']\n",
    "        })\n",
    "\n",
    "        return {\n",
    "            'train_loss': train_losses,\n",
    "            'val_loss': val_losses,\n",
    "            'train_accuracy': train_accuracies,\n",
    "            'val_accuracy': val_accuracies,\n",
    "            **final_metrics\n",
    "        }\n",
    "\n",
    "    def evaluate_metrics(self, data_loader, device):\n",
    "        self.eval()\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in data_loader:\n",
    "                images, labels = images.to(device), labels.to(device).float()\n",
    "                outputs = self(images)\n",
    "                predictions = (torch.sigmoid(outputs) > 0.5).int()\n",
    "                all_preds.extend(predictions.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        hamming = 1 - hamming_loss(all_labels, all_preds)\n",
    "        exact_match_accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "        return {\n",
    "            'hamming_score': hamming,\n",
    "            'exact_match_accuracy': exact_match_accuracy\n",
    "        }\n",
    "\n",
    "def train_sweep():\n",
    "    # Initialize wandb\n",
    "    wandb.init()\n",
    "    \n",
    "    # Get hyperparameters from wandb config\n",
    "    config = wandb.config\n",
    "    \n",
    "    # Initialize model with wandb config\n",
    "    model = CNN(\n",
    "        learning_rate=config.learning_rate,\n",
    "        dropout_rate=config.dropout_rate,\n",
    "        num_conv_layers=config.num_conv_layers,\n",
    "        optimizer_name=config.optimizer,\n",
    "        num_classes=33\n",
    "    )\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Train model and get metrics\n",
    "    metrics = model.train_model(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        num_epochs=config.num_epochs,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Finish run\n",
    "    wandb.finish()\n",
    "\n",
    "# Sweep configuration\n",
    "sweep_config = {\n",
    "    'method': 'grid',\n",
    "    'name': 'cnn-sweep',\n",
    "    'metric': {\n",
    "        'name': 'val_accuracy',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'learning_rate': {'values': [0.001, 0.0001]},\n",
    "        'num_epochs': {'values': [15,20]},\n",
    "        'dropout_rate': {'values': [0.2]},\n",
    "        'num_conv_layers': {'values': [2, 3]},\n",
    "        'optimizer': {'values': ['adam', 'sgd']}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize and run sweep\n",
    "def run_sweep():\n",
    "    wandb.login()\n",
    "    sweep_id = wandb.sweep(sweep_config, project=\"CNN-Multi-Label-Classification\")\n",
    "    wandb.agent(sweep_id, train_sweep, count=16)\n",
    "    \n",
    "run_sweep()    "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5992397,
     "sourceId": 9781263,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
